[2025-09-20T17:45:12.809+0000] {processor.py:161} INFO - Started process (PID=24) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:45:12.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:45:12.815+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:45:12.814+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:45:13.599+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:45:13.593+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:45:13.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:45:13.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.837 seconds
[2025-09-20T17:45:44.468+0000] {processor.py:161} INFO - Started process (PID=28) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:45:44.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:45:44.476+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:45:44.475+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:45:45.019+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:45:45.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:45:45.022+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:45:45.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.610 seconds
[2025-09-20T17:46:15.574+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:46:15.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:46:15.582+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:46:15.582+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:46:16.046+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:46:16.036+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:46:16.049+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:46:16.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.534 seconds
[2025-09-20T17:46:46.452+0000] {processor.py:161} INFO - Started process (PID=34) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:46:46.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:46:46.468+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:46:46.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:46:47.083+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:46:47.075+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:46:47.085+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:46:47.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.694 seconds
[2025-09-20T17:47:17.612+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:47:17.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:47:17.619+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:47:17.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:47:18.367+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:47:18.360+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:47:18.370+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:47:18.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.817 seconds
[2025-09-20T17:47:49.025+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:47:49.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:47:49.030+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:47:49.030+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:47:49.530+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:47:49.517+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:47:49.534+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:47:49.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.601 seconds
[2025-09-20T17:48:19.844+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:48:19.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:48:19.854+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:48:19.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:48:20.318+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:48:20.311+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:48:20.321+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:48:20.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.537 seconds
[2025-09-20T17:48:50.596+0000] {processor.py:161} INFO - Started process (PID=46) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:48:50.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:48:50.601+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:48:50.601+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:48:51.009+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:48:51.001+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:48:51.012+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:48:51.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.474 seconds
[2025-09-20T17:49:21.672+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:49:21.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:49:21.677+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:49:21.676+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:49:22.172+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:49:22.163+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:49:22.175+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:49:22.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.554 seconds
[2025-09-20T17:49:52.313+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:49:52.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:49:52.319+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:49:52.318+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:49:52.745+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:49:52.737+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:49:52.747+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:49:52.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.484 seconds
[2025-09-20T17:50:23.332+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:50:23.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:50:23.336+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:50:23.335+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:50:23.793+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:50:23.785+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:50:23.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:50:23.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.512 seconds
[2025-09-20T17:50:54.348+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:50:54.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:50:54.356+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:50:54.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:50:54.820+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:50:54.812+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:50:54.823+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:50:54.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.550 seconds
[2025-09-20T17:51:25.452+0000] {processor.py:161} INFO - Started process (PID=61) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:51:25.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:51:25.461+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:51:25.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:51:25.923+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:51:25.915+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:51:25.926+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:51:25.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.531 seconds
[2025-09-20T17:51:56.225+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:51:56.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:51:56.233+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:51:56.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:51:56.655+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:51:56.648+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:51:56.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:51:56.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.479 seconds
[2025-09-20T17:52:27.250+0000] {processor.py:161} INFO - Started process (PID=67) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:52:27.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:52:27.258+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:52:27.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:52:27.651+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:52:27.644+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:52:27.653+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:52:27.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.450 seconds
[2025-09-20T17:52:57.989+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:52:57.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:52:57.994+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:52:57.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:52:58.482+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:52:58.475+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:52:58.485+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:52:58.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.549 seconds
[2025-09-20T17:53:29.125+0000] {processor.py:161} INFO - Started process (PID=73) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:53:29.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:53:29.131+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:53:29.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:53:29.616+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:53:29.609+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:53:29.618+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:53:29.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.535 seconds
[2025-09-20T17:53:59.957+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:53:59.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:53:59.973+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:53:59.971+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:54:00.487+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:54:00.475+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:54:00.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:54:00.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.626 seconds
[2025-09-20T17:54:31.210+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:54:31.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:54:31.216+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:54:31.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:54:31.749+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:54:31.740+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:54:31.753+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:54:31.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.605 seconds
[2025-09-20T17:55:02.029+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:55:02.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:55:02.042+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:55:02.041+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:55:02.703+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:55:02.695+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:55:02.705+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:55:02.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.749 seconds
[2025-09-20T17:55:33.458+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:55:33.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:55:33.472+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:55:33.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:55:34.059+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:55:34.051+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:55:34.061+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:55:34.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.662 seconds
[2025-09-20T17:56:04.812+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:56:04.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:56:04.819+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:56:04.818+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:56:05.232+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:56:05.221+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:56:05.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:56:05.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.513 seconds
[2025-09-20T17:56:35.569+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:56:35.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:56:35.575+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:56:35.574+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:56:36.039+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:56:36.030+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:56:36.043+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:56:36.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.540 seconds
[2025-09-20T17:57:06.277+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:57:06.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:57:06.281+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:57:06.281+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:57:06.673+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:57:06.666+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:57:06.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:57:06.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.450 seconds
[2025-09-20T17:57:37.306+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:57:37.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:57:37.311+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:57:37.311+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:57:37.696+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:57:37.689+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:57:37.698+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:57:37.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.430 seconds
[2025-09-20T17:58:07.938+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:58:07.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:58:07.947+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:58:07.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:58:08.361+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:58:08.354+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:58:08.363+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:58:08.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.481 seconds
[2025-09-20T17:58:38.703+0000] {processor.py:161} INFO - Started process (PID=103) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:58:38.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:58:38.711+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:58:38.711+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:58:39.173+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:58:39.165+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:58:39.176+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:58:39.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.516 seconds
[2025-09-20T17:59:09.630+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:59:09.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:59:09.638+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:59:09.637+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:59:10.060+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:59:10.054+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:59:10.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:59:10.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.490 seconds
[2025-09-20T17:59:40.344+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:59:40.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T17:59:40.350+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:59:40.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:59:40.779+0000] {logging_mixin.py:188} INFO - [2025-09-20T17:59:40.772+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T17:59:40.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T17:59:40.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.487 seconds
[2025-09-20T18:00:11.023+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:00:11.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:00:11.039+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:00:11.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:00:11.495+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:00:11.487+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:00:11.498+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:00:11.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.542 seconds
[2025-09-20T18:00:42.038+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:00:42.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:00:42.045+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:00:42.044+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:00:42.486+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:00:42.479+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:00:42.489+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:00:42.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.504 seconds
[2025-09-20T18:01:12.804+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:01:12.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:01:12.810+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:01:12.809+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:01:13.254+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:01:13.247+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:01:13.256+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:01:13.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.508 seconds
[2025-09-20T18:01:43.868+0000] {processor.py:161} INFO - Started process (PID=121) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:01:43.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:01:43.881+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:01:43.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:01:44.250+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:01:44.243+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:01:44.253+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:01:44.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.431 seconds
[2025-09-20T18:02:14.630+0000] {processor.py:161} INFO - Started process (PID=124) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:02:14.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:02:14.639+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:02:14.638+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:02:15.051+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:02:15.044+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:02:15.053+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:02:15.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.493 seconds
[2025-09-20T18:02:45.368+0000] {processor.py:161} INFO - Started process (PID=127) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:02:45.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:02:45.375+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:02:45.374+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:02:45.759+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:02:45.753+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:02:45.762+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:02:45.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.452 seconds
[2025-09-20T18:03:16.483+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:03:16.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:03:16.492+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:03:16.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:03:16.993+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:03:16.981+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:03:16.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:03:17.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.586 seconds
[2025-09-20T18:03:47.352+0000] {processor.py:161} INFO - Started process (PID=133) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:03:47.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:03:47.356+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:03:47.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:03:47.776+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:03:47.769+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:03:47.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:03:47.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.480 seconds
[2025-09-20T18:04:18.447+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:04:18.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:04:18.455+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:04:18.454+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:04:18.971+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:04:18.964+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:04:18.973+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:04:19.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.582 seconds
[2025-09-20T18:04:49.381+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:04:49.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:04:49.387+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:04:49.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:04:49.864+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:04:49.857+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:04:49.867+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:04:49.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.545 seconds
[2025-09-20T18:05:20.660+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:05:20.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:05:20.665+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:05:20.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:05:21.188+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:05:21.180+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:05:21.190+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:05:21.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.596 seconds
[2025-09-20T18:05:51.609+0000] {processor.py:161} INFO - Started process (PID=145) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:05:51.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:05:51.616+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:05:51.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:05:52.087+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:05:52.083+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:05:52.089+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:05:52.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.527 seconds
[2025-09-20T18:06:22.751+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:06:22.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:06:22.756+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:06:22.755+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:06:23.178+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:06:23.166+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:06:23.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:06:23.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.503 seconds
[2025-09-20T18:06:53.855+0000] {processor.py:161} INFO - Started process (PID=151) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:06:53.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:06:53.860+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:06:53.860+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:06:54.242+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:06:54.232+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:06:54.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:06:54.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.457 seconds
[2025-09-20T18:07:24.491+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:07:24.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:07:24.504+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:07:24.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:07:25.126+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:07:25.118+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:07:25.129+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:07:25.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.703 seconds
[2025-09-20T18:07:55.762+0000] {processor.py:161} INFO - Started process (PID=157) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:07:55.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:07:55.766+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:07:55.766+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:07:56.166+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:07:56.154+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:07:56.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:07:56.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.481 seconds
[2025-09-20T18:08:26.797+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:08:26.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:08:26.803+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:08:26.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:08:27.235+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:08:27.228+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:08:27.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:08:27.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.485 seconds
[2025-09-20T18:08:57.427+0000] {processor.py:161} INFO - Started process (PID=163) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:08:57.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:08:57.436+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:08:57.436+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:08:57.873+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:08:57.866+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:08:57.876+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:08:57.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.534 seconds
[2025-09-20T18:09:28.128+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:09:28.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:09:28.132+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:09:28.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:09:28.498+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:09:28.492+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:09:28.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:09:28.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.411 seconds
[2025-09-20T18:09:58.988+0000] {processor.py:161} INFO - Started process (PID=169) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:09:58.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:09:58.992+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:09:58.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:09:59.399+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:09:59.393+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:09:59.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:09:59.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.458 seconds
[2025-09-20T18:10:30.296+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:10:30.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:10:30.300+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:10:30.299+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:10:30.739+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:10:30.725+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:10:30.744+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:10:30.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.521 seconds
[2025-09-20T18:11:01.097+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:11:01.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:11:01.103+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:11:01.103+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:11:01.625+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:11:01.618+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:11:01.628+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:11:01.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.580 seconds
[2025-09-20T18:11:31.882+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:11:31.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:11:31.890+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:11:31.889+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:11:32.417+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:11:32.413+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:11:32.419+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:11:32.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.611 seconds
[2025-09-20T18:12:03.072+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:12:03.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:12:03.077+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:03.077+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:12:03.498+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:03.491+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 5, in <module>
    import minio
ModuleNotFoundError: No module named 'minio'
[2025-09-20T18:12:03.501+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:12:03.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.475 seconds
[2025-09-20T18:12:33.878+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:12:33.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:12:33.883+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:33.883+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:12:34.973+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:34.973+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b5ac5ac0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:12:35.376+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:35.375+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826c75eee70>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:12:36.182+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:36.181+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b017f050>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:12:37.786+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:37.785+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b017f830>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:12:40.992+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:40.991+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b017ffb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:12:41.061+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:12:40.997+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b033a180>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b033a180>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:12:41.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:12:41.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 7.306 seconds
[2025-09-20T18:13:11.903+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:13:11.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:13:11.909+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:11.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:13:12.747+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:12.747+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b17f5af0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:13.149+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:13.149+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b23e60f0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:13.953+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:13.952+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f69c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:15.559+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:15.559+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f6c60>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:18.765+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:18.764+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f74a0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:18.825+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:18.769+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00f79b0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f79b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:13:18.832+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:13:18.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 7.010 seconds
[2025-09-20T18:13:49.475+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:13:49.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:13:49.479+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:49.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:13:50.229+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:50.229+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b23276b0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:50.633+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:50.632+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b2325df0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:51.439+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:51.438+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024e750>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:53.043+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:53.043+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024eb70>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:56.247+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:56.246+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024f050>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:13:56.307+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:13:56.252+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b024f8f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024f8f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:13:56.313+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:13:56.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.885 seconds
[2025-09-20T18:14:27.007+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:14:27.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:14:27.012+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:14:27.011+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:14:27.851+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:14:27.851+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00e6000>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:14:28.255+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:14:28.254+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b01d3530>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:14:29.060+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:14:29.060+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00e6810>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:14:30.666+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:14:30.665+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00e6c30>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:14:33.871+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:14:33.870+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00e7050>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:14:33.932+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:14:33.875+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00e7650>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00e7650>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:14:33.936+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:14:33.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.988 seconds
[2025-09-20T18:15:04.834+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:15:04.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:15:04.841+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:04.840+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:15:05.645+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:05.644+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00e9b80>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:06.048+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:06.047+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b23ee960>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:06.851+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:06.850+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00ea510>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:08.456+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:08.455+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00eaab0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:11.658+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:11.657+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00eb050>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:11.724+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:11.663+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00eb470>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00eb470>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:15:11.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:15:11.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 7.027 seconds
[2025-09-20T18:15:42.689+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:15:42.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:15:42.693+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:42.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:15:43.496+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:43.496+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b23c4650>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:43.898+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:43.898+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b08e2f90>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:44.702+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:44.701+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00ee180>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:46.307+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:46.306+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00ee9c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:49.510+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:49.510+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00eeff0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:15:49.549+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:15:49.513+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00ef4a0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00ef4a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:15:49.554+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:15:49.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.929 seconds
[2025-09-20T18:16:20.529+0000] {processor.py:161} INFO - Started process (PID=228) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:16:20.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:16:20.532+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:20.532+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:16:21.266+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:21.265+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024d940>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:16:21.668+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:21.667+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b02d7ef0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:16:22.469+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:22.469+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024e0c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:16:24.074+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:24.074+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024e360>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:16:27.277+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:27.276+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024eb10>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:16:27.330+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:27.281+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b024eed0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024eed0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:16:27.335+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:16:27.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.861 seconds
[2025-09-20T18:16:58.410+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:16:58.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:16:58.414+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:58.414+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:16:59.153+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:59.153+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b01ff4d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:16:59.556+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:16:59.555+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b02f9550>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:00.360+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:00.360+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024e030>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:01.964+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:01.962+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024e9f0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:05.166+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:05.165+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024ec00>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:05.203+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:05.169+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b024f350>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024f350>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:17:05.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:17:05.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.871 seconds
[2025-09-20T18:17:36.021+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:17:36.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:17:36.029+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:36.029+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:17:36.783+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:36.783+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826c75e9730>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:37.187+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:37.186+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f21e0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:37.992+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:37.991+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f2630>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:39.597+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:39.596+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f2c30>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:42.802+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:42.801+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f30e0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:17:42.862+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:17:42.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00f3950>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f3950>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:17:42.868+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:17:42.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.927 seconds
[2025-09-20T18:18:13.647+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:18:13.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:18:13.651+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:13.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:18:14.494+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:14.494+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826cdf14c80>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:14.897+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:14.896+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b0256900>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:15.702+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:15.701+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f60c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:17.308+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:17.307+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f6750>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:20.514+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:20.512+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f6c90>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:20.562+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:20.521+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00f71a0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f71a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:18:20.569+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:18:20.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.975 seconds
[2025-09-20T18:18:51.290+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:18:51.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:18:51.304+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:51.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:18:52.241+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:52.240+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826cdf146b0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:52.644+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:52.644+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b01fbad0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:53.447+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:53.446+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00fa060>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:55.051+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:55.050+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00fa690>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:58.261+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:58.259+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00fac60>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:18:58.365+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:18:58.273+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00fb350>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00fb350>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:18:58.369+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:18:58.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 7.151 seconds
[2025-09-20T18:19:28.931+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:19:28.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:19:28.935+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:19:28.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:19:29.697+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:19:29.697+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024dc10>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:19:30.100+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:19:30.099+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826c75f2870>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:19:30.904+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:19:30.904+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024e030>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:19:32.507+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:19:32.506+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024eb40>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:19:35.710+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:19:35.709+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024f050>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:19:35.769+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:19:35.714+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b024f650>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024f650>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:19:35.774+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:19:35.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.915 seconds
[2025-09-20T18:20:06.508+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:20:06.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:20:06.512+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:06.512+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:20:07.332+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:07.332+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b14d4fb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:07.736+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:07.735+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b2375670>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:08.542+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:08.541+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024a6f0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:10.148+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:10.147+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024ae10>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:13.352+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:13.352+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024b410>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:13.382+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:13.355+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b024b680>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024b680>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:20:13.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:20:13.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.917 seconds
[2025-09-20T18:20:44.320+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:20:44.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:20:44.324+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:44.324+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:20:45.145+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:45.145+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b236cda0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:45.547+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:45.546+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00e9ca0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:46.350+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:46.349+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00ea180>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:47.954+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:47.953+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00ea720>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:51.158+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:51.157+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00eae70>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:20:51.215+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:20:51.163+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00eb1d0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00eb1d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:20:51.222+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:20:51.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 7.016 seconds
[2025-09-20T18:21:22.031+0000] {processor.py:161} INFO - Started process (PID=255) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:21:22.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:21:22.040+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:21:22.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:21:23.003+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:21:23.003+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b0452ae0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:21:23.407+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:21:23.406+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b2335670>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:21:24.210+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:21:24.210+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f2d50>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:21:25.814+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:21:25.813+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f3050>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:21:29.018+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:21:29.017+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f3650>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:21:29.052+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:21:29.022+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00f3950>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f3950>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:21:29.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:21:29.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 7.096 seconds
[2025-09-20T18:21:59.904+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:21:59.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:21:59.909+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:21:59.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:22:00.828+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:00.828+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826c7491c10>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:01.231+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:01.230+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b08dffb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:02.035+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:02.035+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f6750>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:03.638+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:03.637+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f6ba0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:06.841+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:06.840+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f72c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:06.907+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:06.846+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00f7650>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f7650>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:22:06.913+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:22:06.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 7.069 seconds
[2025-09-20T18:22:37.784+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:22:37.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:22:37.789+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:37.788+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:22:38.634+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:38.634+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b0bbcf80>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:39.037+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:39.036+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b0233530>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:39.842+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:39.842+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024e8d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:41.448+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:41.447+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024ee40>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:44.653+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:44.652+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024f260>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:22:44.692+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:22:44.656+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b024f9e0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b024f9e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:22:44.697+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:22:44.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.989 seconds
[2025-09-20T18:23:15.484+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:23:15.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:23:15.490+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:23:15.490+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:23:16.351+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:23:16.329+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710BFFF739AF8, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710BFFF739AF8, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:23:16.356+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:23:16.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.924 seconds
[2025-09-20T18:23:47.268+0000] {processor.py:161} INFO - Started process (PID=268) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:23:47.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:23:47.274+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:23:47.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:23:48.203+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:23:48.168+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710C7697FD7CD, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710C7697FD7CD, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:23:48.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:23:48.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.994 seconds
[2025-09-20T18:24:18.932+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:24:18.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:24:18.936+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:24:18.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:24:19.871+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:24:19.852+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710CECA1549FE, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710CECA1549FE, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:24:19.876+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:24:19.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.990 seconds
[2025-09-20T18:24:50.576+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:24:50.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:24:50.581+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:24:50.581+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:24:51.495+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:24:51.465+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710D626554BB3, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710D626554BB3, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:24:51.503+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:24:51.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.004 seconds
[2025-09-20T18:25:22.279+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:25:22.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:25:22.287+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:25:22.286+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:25:23.217+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:25:23.200+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710DD89DAE220, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710DD89DAE220, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:25:23.221+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:25:23.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.995 seconds
[2025-09-20T18:25:53.872+0000] {processor.py:161} INFO - Started process (PID=280) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:25:53.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:25:53.878+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:25:53.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:25:54.740+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:25:54.714+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710E4E04398AC, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710E4E04398AC, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:25:54.748+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:25:54.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.941 seconds
[2025-09-20T18:26:25.473+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:26:25.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:26:25.483+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:26:25.482+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:26:26.425+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:26:26.408+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710EC41519BE4, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710EC41519BE4, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:26:26.430+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:26:26.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.026 seconds
[2025-09-20T18:26:57.025+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:26:57.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:26:57.029+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:26:57.029+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:26:58.037+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:26:58.013+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710F39D189D76, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710F39D189D76, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:26:58.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:26:58.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.105 seconds
[2025-09-20T18:27:28.755+0000] {processor.py:161} INFO - Started process (PID=289) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:27:28.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:27:28.761+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:27:28.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:27:29.764+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:27:29.730+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710FAFF828D32, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186710FAFF828D32, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:27:29.771+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:27:29.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.093 seconds
[2025-09-20T18:28:00.497+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:28:00.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:28:00.507+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:28:00.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:28:01.578+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:28:01.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867110268AB91C2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867110268AB91C2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:28:01.583+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:28:01.615+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.170 seconds
[2025-09-20T18:28:32.293+0000] {processor.py:161} INFO - Started process (PID=295) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:28:32.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:28:32.299+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:28:32.298+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:28:33.211+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:28:33.197+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671109C69784BC, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671109C69784BC, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:28:33.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:28:33.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.971 seconds
[2025-09-20T18:29:03.884+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:29:03.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:29:03.888+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:29:03.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:29:04.794+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:29:04.759+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711111FBA5D39, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711111FBA5D39, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:29:04.802+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:29:04.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.967 seconds
[2025-09-20T18:29:35.525+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:29:35.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:29:35.533+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:29:35.532+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:29:36.307+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:29:36.286+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711187700985C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711187700985C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:29:36.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:29:36.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.863 seconds
[2025-09-20T18:30:07.138+0000] {processor.py:161} INFO - Started process (PID=304) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:30:07.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:30:07.143+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:30:07.142+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:30:07.977+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:30:07.958+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867111FD6CD73DB, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867111FD6CD73DB, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:30:07.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:30:08.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.912 seconds
[2025-09-20T18:30:38.878+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:30:38.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:30:38.882+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:30:38.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:30:39.764+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:30:39.728+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711273C548234, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711273C548234, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:30:39.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:30:39.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.960 seconds
[2025-09-20T18:31:10.679+0000] {processor.py:161} INFO - Started process (PID=311) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:31:10.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:31:10.684+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:31:10.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:31:11.632+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:31:11.597+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867112EA7DDD328, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867112EA7DDD328, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:31:11.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:31:11.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.049 seconds
[2025-09-20T18:31:42.288+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:31:42.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:31:42.292+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:31:42.292+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:31:43.058+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:31:43.038+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671135FA069486, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671135FA069486, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:31:43.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:31:43.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.818 seconds
[2025-09-20T18:32:13.850+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:32:13.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:32:13.858+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:32:13.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:32:14.883+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:32:14.845+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867113D61C3B664, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867113D61C3B664, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:32:14.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:32:14.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.147 seconds
[2025-09-20T18:32:45.517+0000] {processor.py:161} INFO - Started process (PID=320) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:32:45.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:32:45.525+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:32:45.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:32:46.477+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:32:46.441+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671144BD021FC7, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671144BD021FC7, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:32:46.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:32:46.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.037 seconds
[2025-09-20T18:33:17.203+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:33:17.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:33:17.211+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:33:17.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:33:18.144+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:33:18.116+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867114C1CD71058, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867114C1CD71058, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:33:18.148+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:33:18.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.005 seconds
[2025-09-20T18:33:48.838+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:33:48.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:33:48.845+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:33:48.845+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:33:49.690+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:33:49.670+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867115375D02DEB, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867115375D02DEB, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:33:49.694+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:33:49.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.919 seconds
[2025-09-20T18:34:20.485+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:34:20.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:34:20.492+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:34:20.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:34:21.338+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:34:21.326+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867115AD4B1B015, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867115AD4B1B015, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:34:21.340+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:34:21.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.904 seconds
[2025-09-20T18:34:52.166+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:34:52.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:34:52.180+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:34:52.179+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:34:53.557+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:34:53.544+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867116255020D9C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867116255020D9C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:34:53.560+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:34:53.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.467 seconds
[2025-09-20T18:35:24.263+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:35:24.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:35:24.272+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:35:24.270+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:35:25.184+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:35:25.170+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671169B211F6FA, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671169B211F6FA, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:35:25.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:35:25.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.978 seconds
[2025-09-20T18:35:55.854+0000] {processor.py:161} INFO - Started process (PID=338) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:35:55.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:35:55.863+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:35:55.862+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:35:56.691+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:35:56.667+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671171077AABED, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671171077AABED, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:35:56.699+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:35:56.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.936 seconds
[2025-09-20T18:36:27.367+0000] {processor.py:161} INFO - Started process (PID=341) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:36:27.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:36:27.371+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:36:27.371+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:36:28.268+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:36:28.250+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 8, in <module>
    from src.Lake.lake_connection import get_minio_client
  File "/opt/airflow/src/Lake/lake_connection.py", line 20, in <module>
    for obj in client.list_objects("myback", recursive=True):
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 3322, in _list_objects
    response = self._execute(
               ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /myback, request_id: 18671178620079A2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: myback
[2025-09-20T18:36:28.269+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:36:28.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.943 seconds
[2025-09-20T18:36:58.978+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:36:58.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:36:58.984+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:36:58.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:36:59.785+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:36:59.769+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 8, in <module>
    from src.Lake.lake_connection import get_minio_client
  File "/opt/airflow/src/Lake/lake_connection.py", line 20, in <module>
    for obj in client.list_objects("myback", recursive=True):
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 3322, in _list_objects
    response = self._execute(
               ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /myback, request_id: 1867117FB8A75FC2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: myback
[2025-09-20T18:36:59.788+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:36:59.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.892 seconds
[2025-09-20T18:37:30.699+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:37:30.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:37:30.705+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:37:30.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:37:31.604+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:37:31.576+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 8, in <module>
    from src.Lake.lake_connection import get_minio_client
  File "/opt/airflow/src/Lake/lake_connection.py", line 20, in <module>
    for obj in client.list_objects("myback", recursive=True):
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 3322, in _list_objects
    response = self._execute(
               ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /myback, request_id: 18671187206D3CCF, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: myback
[2025-09-20T18:37:31.607+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:37:31.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.985 seconds
[2025-09-20T18:38:02.395+0000] {processor.py:161} INFO - Started process (PID=350) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:38:02.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:38:02.401+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:38:02.400+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:38:03.248+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:38:03.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 8, in <module>
    from src.Lake.lake_connection import get_minio_client
  File "/opt/airflow/src/Lake/lake_connection.py", line 20, in <module>
    for obj in client.list_objects("myback", recursive=True):
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 3322, in _list_objects
    response = self._execute(
               ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /myback, request_id: 1867118E7E63E8A8, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: myback
[2025-09-20T18:38:03.251+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:38:03.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.951 seconds
[2025-09-20T18:38:33.883+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:38:33.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:38:33.887+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:38:33.887+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:38:34.709+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:38:34.694+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 8, in <module>
    from src.Lake.lake_connection import get_minio_client
  File "/opt/airflow/src/Lake/lake_connection.py", line 20, in <module>
    for obj in client.list_objects("myback", recursive=True):
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 3322, in _list_objects
    response = self._execute(
               ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /myback, request_id: 18671195D29D9A3E, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: myback
[2025-09-20T18:38:34.710+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:38:34.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.868 seconds
[2025-09-20T18:39:05.428+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:39:05.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:39:05.441+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:05.440+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:39:06.356+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:06.356+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b23e3cb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /myback?delimiter=&encoding-type=url&list-type=2&max-keys=1000&prefix=
[2025-09-20T18:39:06.759+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:06.758+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b2365670>: Failed to establish a new connection: [Errno 111] Connection refused')': /myback?delimiter=&encoding-type=url&list-type=2&max-keys=1000&prefix=
[2025-09-20T18:39:07.565+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:07.564+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00ea300>: Failed to establish a new connection: [Errno 111] Connection refused')': /myback?delimiter=&encoding-type=url&list-type=2&max-keys=1000&prefix=
[2025-09-20T18:39:09.170+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:09.169+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00ea600>: Failed to establish a new connection: [Errno 111] Connection refused')': /myback?delimiter=&encoding-type=url&list-type=2&max-keys=1000&prefix=
[2025-09-20T18:39:12.376+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:12.375+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00eb050>: Failed to establish a new connection: [Errno 111] Connection refused')': /myback?delimiter=&encoding-type=url&list-type=2&max-keys=1000&prefix=
[2025-09-20T18:39:12.407+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:12.380+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00eb560>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 8, in <module>
    from src.Lake.lake_connection import get_minio_client
  File "/opt/airflow/src/Lake/lake_connection.py", line 20, in <module>
    for obj in client.list_objects("myback", recursive=True):
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 3322, in _list_objects
    response = self._execute(
               ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /myback?delimiter=&encoding-type=url&list-type=2&max-keys=1000&prefix= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00eb560>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:39:12.409+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:39:12.440+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 7.083 seconds
[2025-09-20T18:39:42.990+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:39:42.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:39:42.994+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:42.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:39:43.802+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:43.802+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b2394b60>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:39:44.205+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:44.204+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b09ef9e0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:39:45.009+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:45.008+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f6180>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:39:46.611+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:46.610+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f6750>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:39:49.813+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:49.813+0000] {connectionpool.py:872} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f6ed0>: Failed to establish a new connection: [Errno 111] Connection refused')': /mybucket/users.csv
[2025-09-20T18:39:49.855+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:39:49.816+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7826b00f7470>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 305, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 875, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /mybucket/users.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7826b00f7470>: Failed to establish a new connection: [Errno 111] Connection refused'))
[2025-09-20T18:39:49.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:39:49.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 6.953 seconds
[2025-09-20T18:40:20.093+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:40:20.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:40:20.099+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:40:20.098+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:40:20.943+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:40:20.930+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711AE8EBF92B6, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711AE8EBF92B6, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:40:20.946+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:40:20.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.902 seconds
[2025-09-20T18:40:51.654+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:40:51.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:40:51.658+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:40:51.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:40:52.530+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:40:52.502+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711B5E87E0F0C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711B5E87E0F0C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:40:52.537+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:40:52.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.946 seconds
[2025-09-20T18:41:23.455+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:41:23.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:41:23.462+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:41:23.461+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:41:24.351+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:41:24.333+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711BD51DCE8C1, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711BD51DCE8C1, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:41:24.354+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:41:24.390+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.966 seconds
[2025-09-20T18:41:54.931+0000] {processor.py:161} INFO - Started process (PID=372) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:41:54.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:41:54.936+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:41:54.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:41:55.794+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:41:55.764+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711C4A3384106, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711C4A3384106, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:41:55.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:41:55.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.918 seconds
[2025-09-20T18:42:26.635+0000] {processor.py:161} INFO - Started process (PID=375) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:42:26.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:42:26.640+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:42:26.639+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:42:27.432+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:42:27.412+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711CC01B74E55, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711CC01B74E55, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:42:27.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:42:27.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.850 seconds
[2025-09-20T18:42:58.287+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:42:58.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:42:58.292+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:42:58.292+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:42:59.207+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:42:59.180+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711D367271AD4, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711D367271AD4, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:42:59.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:42:59.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.989 seconds
[2025-09-20T18:43:29.985+0000] {processor.py:161} INFO - Started process (PID=381) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:43:29.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:43:29.990+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:43:29.989+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:43:30.917+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:43:30.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711DAC97A5558, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711DAC97A5558, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:43:30.921+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:43:30.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.990 seconds
[2025-09-20T18:44:01.597+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:44:01.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:44:01.603+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:44:01.602+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:44:02.443+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:44:02.408+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711E21FC5E54B, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711E21FC5E54B, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:44:02.451+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:44:02.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.931 seconds
[2025-09-20T18:44:33.383+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:44:33.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:44:33.388+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:44:33.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:44:34.234+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:44:34.218+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711E987E2E5E1, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711E987E2E5E1, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:44:34.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:44:34.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.913 seconds
[2025-09-20T18:45:04.921+0000] {processor.py:161} INFO - Started process (PID=390) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:45:04.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:45:04.925+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:45:04.924+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:45:05.797+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:45:05.761+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711F0DFEAFB76, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711F0DFEAFB76, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:45:05.805+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:45:05.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.952 seconds
[2025-09-20T18:45:36.757+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:45:36.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:45:36.763+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:45:36.762+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:45:37.611+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:45:37.592+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711F849492952, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711F849492952, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:45:37.615+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:45:37.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.912 seconds
[2025-09-20T18:46:08.386+0000] {processor.py:161} INFO - Started process (PID=396) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:46:08.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:46:08.390+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:46:08.390+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:46:09.179+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:46:09.147+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711FFA21EED0C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 186711FFA21EED0C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:46:09.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:46:09.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.870 seconds
[2025-09-20T18:46:39.917+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:46:39.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:46:39.923+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:46:39.923+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:46:40.958+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:46:40.937+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867120708F46C80, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867120708F46C80, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:46:40.963+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:46:40.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.103 seconds
[2025-09-20T18:47:11.603+0000] {processor.py:161} INFO - Started process (PID=402) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:47:11.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:47:11.609+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:47:11.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:47:12.483+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:47:12.463+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867120E600B7E69, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867120E600B7E69, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:47:12.487+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:47:12.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.936 seconds
[2025-09-20T18:47:43.185+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:47:43.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:47:43.190+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:47:43.190+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:47:44.023+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:47:43.983+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671215B6AAADCD, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671215B6AAADCD, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:47:44.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:47:44.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.898 seconds
[2025-09-20T18:48:14.807+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:48:14.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:48:14.812+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:48:14.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:48:15.719+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:48:15.683+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867121D1829E1DC, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867121D1829E1DC, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:48:15.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:48:15.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.985 seconds
[2025-09-20T18:48:46.376+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:48:46.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:48:46.380+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:48:46.380+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:48:47.111+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:48:47.092+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671224685D3032, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671224685D3032, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:48:47.117+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:48:47.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.814 seconds
[2025-09-20T18:49:17.876+0000] {processor.py:161} INFO - Started process (PID=414) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:49:17.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:49:17.882+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:49:17.881+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:49:18.782+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:49:18.754+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867122BC789AAB2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867122BC789AAB2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:49:18.788+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:49:18.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.974 seconds
[2025-09-20T18:49:49.500+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:49:49.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:49:49.505+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:49:49.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:49:50.423+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:49:50.396+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867123325762AF0, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867123325762AF0, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:49:50.427+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:49:50.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.998 seconds
[2025-09-20T18:50:21.214+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:50:21.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:50:21.221+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:50:21.220+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:50:22.051+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:50:22.021+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867123A8292535A, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 1867123A8292535A, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:50:22.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:50:22.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.904 seconds
[2025-09-20T18:50:52.838+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:50:52.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:50:52.842+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:50:52.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:50:53.634+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:50:53.615+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671241DDB3376B, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671241DDB3376B, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:50:53.638+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:50:53.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.839 seconds
[2025-09-20T18:51:24.470+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:51:24.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:51:24.483+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:51:24.482+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:51:26.341+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:51:26.292+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671249794306A2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671249794306A2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:51:26.352+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:51:26.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 2.051 seconds
[2025-09-20T18:51:57.124+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:51:57.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:51:57.127+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:51:57.127+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:51:57.672+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:51:57.661+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/opt/airflow/src/etl/extract.py", line 9, in extract_from_lake
    response = minio_client.get_object(bucket_name, object_name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 1256, in get_object
    return self._execute(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 443, in _execute
    return self._url_open(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/minio/api.py", line 426, in _url_open
    raise response_error
minio.error.S3Error: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671250C72D3871, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 9, in <module>
    from src.etl.extract import extract_from_lake
  File "/opt/airflow/src/etl/extract.py", line 21, in <module>
    df_users = extract_from_lake(minio_client, "mybucket", "users.csv")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/etl/extract.py", line 17, in extract_from_lake
    raise RuntimeError(f"Can't download {object_name} from {bucket_name}: {e}")
RuntimeError: Can't download users.csv from mybucket: S3 operation failed; code: AccessDenied, message: Access Denied., resource: /mybucket/users.csv, request_id: 18671250C72D3871, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: mybucket, object_name: users.csv
[2025-09-20T18:51:57.674+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:51:57.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.579 seconds
[2025-09-20T18:52:27.771+0000] {processor.py:161} INFO - Started process (PID=432) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:52:27.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:52:27.774+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:27.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:52:28.388+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:52:28.533+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:52:28.663+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:28.662+0000] {override.py:1858} INFO - Created Permission View: can read on DAG:clean_users_from_lake_dag
[2025-09-20T18:52:28.677+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:28.677+0000] {override.py:1858} INFO - Created Permission View: can edit on DAG:clean_users_from_lake_dag
[2025-09-20T18:52:28.684+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:28.683+0000] {override.py:1858} INFO - Created Permission View: can delete on DAG:clean_users_from_lake_dag
[2025-09-20T18:52:28.685+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:28.685+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:52:28.695+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:28.695+0000] {dag.py:3111} INFO - Creating ORM DAG for clean_users_from_lake_dag
[2025-09-20T18:52:28.696+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:28.696+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:52:28.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.957 seconds
[2025-09-20T18:52:59.141+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:52:59.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:52:59.144+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:59.144+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:52:59.693+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:52:59.755+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:52:59.782+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:59.781+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:52:59.791+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:52:59.791+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:52:59.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.680 seconds
[2025-09-20T18:53:30.368+0000] {processor.py:161} INFO - Started process (PID=438) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:53:30.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:53:30.372+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:53:30.371+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:53:30.951+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:53:31.011+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:53:31.037+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:53:31.037+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:53:31.046+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:53:31.046+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:53:31.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.707 seconds
[2025-09-20T18:54:01.740+0000] {processor.py:161} INFO - Started process (PID=471) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:54:01.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:54:01.746+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:54:01.746+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:54:02.460+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:54:02.528+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:54:02.554+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:54:02.554+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:54:02.563+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:54:02.563+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:54:02.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.852 seconds
[2025-09-20T18:54:33.064+0000] {processor.py:161} INFO - Started process (PID=474) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:54:33.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:54:33.067+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:54:33.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:54:33.632+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:54:33.690+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:54:33.716+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:54:33.715+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:54:33.726+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:54:33.726+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:54:33.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.690 seconds
[2025-09-20T18:55:04.410+0000] {processor.py:161} INFO - Started process (PID=477) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:55:04.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:55:04.414+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:55:04.414+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:55:05.019+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:55:05.079+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:55:05.104+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:55:05.103+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:55:05.113+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:55:05.113+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:55:05.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.745 seconds
[2025-09-20T18:55:35.864+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:55:35.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:55:35.868+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:55:35.867+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:55:36.411+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:55:36.464+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:55:36.490+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:55:36.490+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:55:36.498+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:55:36.498+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:55:36.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.662 seconds
[2025-09-20T18:56:07.169+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:56:07.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:56:07.173+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:56:07.173+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:56:07.742+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:56:07.810+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:56:07.837+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:56:07.837+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:56:07.847+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:56:07.847+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:56:07.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.708 seconds
[2025-09-20T18:56:38.578+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:56:38.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:56:38.581+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:56:38.581+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:56:39.144+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:56:39.204+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:56:39.229+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:56:39.229+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:56:39.238+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:56:39.238+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:56:39.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.688 seconds
[2025-09-20T18:57:09.957+0000] {processor.py:161} INFO - Started process (PID=490) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:57:09.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:57:09.960+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:57:09.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:57:10.575+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:57:10.646+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:57:10.676+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:57:10.676+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:57:10.686+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:57:10.686+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:57:10.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.761 seconds
[2025-09-20T18:57:41.325+0000] {processor.py:161} INFO - Started process (PID=493) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:57:41.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:57:41.328+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:57:41.328+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:57:41.936+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:57:42.225+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:57:42.273+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:57:42.272+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:57:42.288+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:57:42.288+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:57:42.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.001 seconds
[2025-09-20T18:58:12.570+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:58:12.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:58:12.574+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:58:12.573+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:58:13.175+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:58:13.252+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:58:13.281+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:58:13.281+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:58:13.294+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:58:13.294+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:58:13.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.757 seconds
[2025-09-20T18:58:43.900+0000] {processor.py:161} INFO - Started process (PID=499) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:58:43.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:58:43.903+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:58:43.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:58:44.544+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:58:44.628+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:58:44.658+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:58:44.658+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:58:44.668+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:58:44.668+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:58:44.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.804 seconds
[2025-09-20T18:59:15.249+0000] {processor.py:161} INFO - Started process (PID=502) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:59:15.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:59:15.253+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:59:15.252+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:59:15.875+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:59:15.942+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:59:15.970+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:59:15.969+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:59:15.979+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:59:15.979+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:59:15.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T18:59:46.672+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:59:46.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T18:59:46.675+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:59:46.675+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:59:47.274+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T18:59:47.327+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T18:59:47.355+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:59:47.355+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T18:59:47.366+0000] {logging_mixin.py:188} INFO - [2025-09-20T18:59:47.366+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T18:59:47.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.724 seconds
[2025-09-20T19:00:18.057+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:00:18.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:00:18.060+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:00:18.060+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:00:18.618+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:00:18.688+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:00:18.715+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:00:18.715+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:00:18.725+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:00:18.725+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:00:18.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.697 seconds
[2025-09-20T19:00:49.389+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:00:49.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:00:49.392+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:00:49.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:00:50.001+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:00:50.059+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:00:50.086+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:00:50.085+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:00:50.096+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:00:50.096+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:00:50.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.737 seconds
[2025-09-20T19:01:20.741+0000] {processor.py:161} INFO - Started process (PID=544) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:01:20.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:01:20.744+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:01:20.744+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:01:21.321+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:01:21.382+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:01:21.410+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:01:21.409+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:01:21.420+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:01:21.419+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:01:21.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.709 seconds
[2025-09-20T19:01:52.100+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:01:52.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:01:52.103+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:01:52.103+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:01:52.754+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:01:52.820+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:01:52.848+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:01:52.847+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:01:52.858+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:01:52.857+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:01:52.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.789 seconds
[2025-09-20T19:02:23.462+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:02:23.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:02:23.466+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:02:23.466+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:02:24.081+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:02:24.153+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:02:24.180+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:02:24.180+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:02:24.190+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:02:24.190+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:02:24.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.760 seconds
[2025-09-20T19:02:54.830+0000] {processor.py:161} INFO - Started process (PID=553) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:02:54.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:02:54.834+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:02:54.834+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:02:55.471+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:02:55.543+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:02:55.570+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:02:55.570+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:02:55.580+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:02:55.580+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:02:55.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.783 seconds
[2025-09-20T19:03:26.166+0000] {processor.py:161} INFO - Started process (PID=556) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:03:26.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:03:26.169+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:03:26.168+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:03:26.764+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:03:26.833+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:03:26.860+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:03:26.860+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:03:26.870+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:03:26.870+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:03:26.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.734 seconds
[2025-09-20T19:03:57.556+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:03:57.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:03:57.559+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:03:57.559+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:03:58.162+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:03:58.221+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:03:58.248+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:03:58.248+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:03:58.258+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:03:58.258+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:03:58.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.732 seconds
[2025-09-20T19:04:28.900+0000] {processor.py:161} INFO - Started process (PID=562) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:04:28.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:04:28.903+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:04:28.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:04:29.764+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:04:29.812+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:04:29.840+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:04:29.839+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:04:29.849+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:04:29.849+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:04:29.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.980 seconds
[2025-09-20T19:05:00.142+0000] {processor.py:161} INFO - Started process (PID=565) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:05:00.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:05:00.146+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:05:00.145+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:05:00.796+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:05:00.857+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:05:00.886+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:05:00.886+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:05:00.897+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:05:00.897+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:05:00.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.793 seconds
[2025-09-20T19:05:31.527+0000] {processor.py:161} INFO - Started process (PID=568) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:05:31.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:05:31.531+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:05:31.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:05:32.100+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:05:32.158+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:05:32.186+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:05:32.186+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:05:32.196+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:05:32.196+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:05:32.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.702 seconds
[2025-09-20T19:06:02.840+0000] {processor.py:161} INFO - Started process (PID=571) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:06:02.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:06:02.843+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:06:02.843+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:06:03.463+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:06:03.529+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:06:03.557+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:06:03.556+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:06:03.569+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:06:03.569+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:06:03.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.761 seconds
[2025-09-20T19:06:34.191+0000] {processor.py:161} INFO - Started process (PID=574) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:06:34.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:06:34.195+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:06:34.195+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:06:34.825+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:06:34.886+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:06:34.914+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:06:34.914+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:06:34.925+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:06:34.925+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:06:34.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.773 seconds
[2025-09-20T19:07:05.535+0000] {processor.py:161} INFO - Started process (PID=577) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:07:05.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:07:05.539+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:07:05.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:07:06.095+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:07:06.159+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:07:06.186+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:07:06.185+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:07:06.195+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:07:06.195+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:07:06.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.690 seconds
[2025-09-20T19:07:36.932+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:07:36.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:07:36.939+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:07:36.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:07:37.548+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:07:37.622+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:07:37.649+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:07:37.648+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:07:37.658+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:07:37.658+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:07:37.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.756 seconds
[2025-09-20T19:08:08.259+0000] {processor.py:161} INFO - Started process (PID=583) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:08:08.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:08:08.262+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:08:08.262+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:08:08.837+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:08:08.904+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:08:08.929+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:08:08.929+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:08:08.938+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:08:08.938+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:08:08.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.708 seconds
[2025-09-20T19:08:39.601+0000] {processor.py:161} INFO - Started process (PID=586) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:08:39.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:08:39.605+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:08:39.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:08:40.170+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:08:40.231+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:08:40.258+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:08:40.258+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:08:40.268+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:08:40.268+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:08:40.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.706 seconds
[2025-09-20T19:09:10.944+0000] {processor.py:161} INFO - Started process (PID=589) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:09:10.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:09:10.948+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:09:10.948+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:09:11.501+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:09:11.563+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:09:11.590+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:09:11.590+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:09:11.601+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:09:11.600+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:09:11.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.685 seconds
[2025-09-20T19:09:42.297+0000] {processor.py:161} INFO - Started process (PID=592) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:09:42.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:09:42.300+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:09:42.300+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:09:43.000+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:09:43.045+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:09:43.072+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:09:43.071+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:09:43.082+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:09:43.082+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:09:43.108+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.822 seconds
[2025-09-20T19:10:13.631+0000] {processor.py:161} INFO - Started process (PID=595) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:10:13.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:10:13.634+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:10:13.634+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:10:14.224+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:10:14.284+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:10:14.312+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:10:14.312+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:10:14.323+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:10:14.322+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:10:14.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.729 seconds
[2025-09-20T19:10:44.984+0000] {processor.py:161} INFO - Started process (PID=598) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:10:44.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:10:44.987+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:10:44.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:10:45.665+0000] {logging_mixin.py:188} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:10:45.743+0000] {processor.py:840} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:10:45.769+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:10:45.769+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-09-20T19:10:45.779+0000] {logging_mixin.py:188} INFO - [2025-09-20T19:10:45.779+0000] {dag.py:3947} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:10:45.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.834 seconds
[2025-09-20T19:23:20.872+0000] {processor.py:186} INFO - Started process (PID=24) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:23:20.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:23:20.877+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:23:20.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:23:21.653+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:23:21.708+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:23:21.728+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:23:21.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:23:21.752+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:23:21.752+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:23:21.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.918 seconds
[2025-09-20T19:23:52.264+0000] {processor.py:186} INFO - Started process (PID=28) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:23:52.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:23:52.268+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:23:52.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:23:53.160+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:23:53.243+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:23:53.389+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:23:53.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:23:53.410+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:23:53.409+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:23:53.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.203 seconds
[2025-09-20T19:24:23.768+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:24:23.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:24:23.772+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:24:23.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:24:24.483+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:24:24.560+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:24:24.587+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:24:24.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:24:24.600+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:24:24.600+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:24:24.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.869 seconds
[2025-09-20T19:24:54.946+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:24:54.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:24:54.950+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:24:54.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:24:55.577+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:24:55.644+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:24:55.670+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:24:55.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:24:55.682+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:24:55.681+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:24:55.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.762 seconds
[2025-09-20T19:25:26.368+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:25:26.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:25:26.373+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:25:26.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:25:27.311+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:25:27.373+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:25:27.406+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:25:27.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:25:27.424+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:25:27.424+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:25:27.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.085 seconds
[2025-09-20T19:25:57.725+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:25:57.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:25:57.729+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:25:57.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:25:58.349+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:25:58.417+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:25:58.444+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:25:58.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:25:58.455+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:25:58.455+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:25:58.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.756 seconds
[2025-09-20T19:26:28.842+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:26:28.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:26:28.847+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:26:28.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:26:29.452+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:26:29.510+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:26:29.535+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:26:29.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:26:29.546+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:26:29.546+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:26:29.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.732 seconds
[2025-09-20T19:27:00.242+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:27:00.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:27:00.246+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:27:00.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:27:00.886+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:27:00.971+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:27:00.999+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:27:00.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:27:01.011+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:27:01.011+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:27:01.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.797 seconds
[2025-09-20T19:27:31.642+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:27:31.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:27:31.647+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:27:31.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:27:32.262+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:27:32.345+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:27:32.378+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:27:32.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:27:32.392+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:27:32.392+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:27:32.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.779 seconds
[2025-09-20T19:28:03.041+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:28:03.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:28:03.045+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:28:03.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:28:03.745+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:28:03.808+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:28:03.836+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:28:03.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:28:03.848+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:28:03.848+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:28:03.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.836 seconds
[2025-09-20T19:28:34.500+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:28:34.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:28:34.504+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:28:34.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:28:35.085+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:28:35.155+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:28:35.179+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:28:35.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:28:35.189+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:28:35.189+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:28:35.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.715 seconds
[2025-09-20T19:29:05.904+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:29:05.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:29:05.909+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:29:05.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:29:06.515+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:29:06.591+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:29:06.616+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:29:06.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:29:06.628+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:29:06.627+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:29:06.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.750 seconds
[2025-09-20T19:29:37.295+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:29:37.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:29:37.299+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:29:37.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:29:37.982+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:29:38.075+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:29:38.100+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:29:38.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:29:38.112+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:29:38.112+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:29:38.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.842 seconds
[2025-09-20T19:30:08.694+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:30:08.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:30:08.697+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:30:08.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:30:09.301+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:30:09.360+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:30:09.385+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:30:09.384+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:30:09.396+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:30:09.395+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:30:09.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.737 seconds
[2025-09-20T19:30:40.096+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:30:40.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:30:40.100+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:30:40.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:30:40.684+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:30:40.744+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:30:40.768+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:30:40.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:30:40.778+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:30:40.778+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:30:40.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.708 seconds
[2025-09-20T19:31:11.497+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:31:11.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:31:11.501+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:31:11.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:31:12.089+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:31:12.155+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:31:12.181+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:31:12.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:31:12.193+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:31:12.193+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:31:12.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.722 seconds
[2025-09-20T19:31:42.897+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:31:42.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:31:42.901+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:31:42.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:31:43.512+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:31:43.577+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:31:43.603+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:31:43.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:31:43.616+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:31:43.616+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:31:43.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.749 seconds
[2025-09-20T19:32:14.288+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:32:14.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:32:14.292+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:32:14.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:32:14.912+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:32:14.980+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:32:15.008+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:32:15.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:32:15.020+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:32:15.020+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:32:15.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T19:32:45.746+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:32:45.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:32:45.751+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:32:45.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:32:46.325+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:32:46.377+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:32:46.402+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:32:46.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:32:46.413+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:32:46.413+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:32:46.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.692 seconds
[2025-09-20T19:33:17.125+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:33:17.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:33:17.129+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:33:17.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:33:17.844+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:33:17.919+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:33:17.967+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:33:17.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:33:17.994+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:33:17.994+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:33:18.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.903 seconds
[2025-09-20T19:33:48.487+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:33:48.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:33:48.491+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:33:48.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:33:49.116+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:33:49.179+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:33:49.205+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:33:49.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:33:49.217+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:33:49.216+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:33:49.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.757 seconds
[2025-09-20T19:34:19.855+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:34:19.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:34:19.860+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:34:19.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:34:20.641+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:34:20.701+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:34:20.728+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:34:20.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:34:20.742+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:34:20.741+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:34:20.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.927 seconds
[2025-09-20T19:34:51.099+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:34:51.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:34:51.103+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:34:51.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:34:51.805+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:34:51.867+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:34:51.896+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:34:51.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:34:51.910+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:34:51.910+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:34:51.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.841 seconds
[2025-09-20T19:35:22.533+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:35:22.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:35:22.537+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:35:22.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:35:23.182+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:35:23.238+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:35:23.267+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:35:23.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:35:23.281+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:35:23.281+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:35:23.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.777 seconds
[2025-09-20T19:35:53.933+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:35:53.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:35:53.937+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:35:53.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:35:54.620+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:35:54.674+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:35:54.700+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:35:54.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:35:54.711+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:35:54.711+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:35:54.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.809 seconds
[2025-09-20T19:36:25.355+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:36:25.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:36:25.359+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:36:25.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:36:25.985+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:36:26.048+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:36:26.074+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:36:26.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:36:26.086+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:36:26.085+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:36:26.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.766 seconds
[2025-09-20T19:36:56.759+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:36:56.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:36:56.763+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:36:56.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:36:57.381+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:36:57.438+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:36:57.463+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:36:57.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:36:57.475+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:36:57.474+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:36:57.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.745 seconds
[2025-09-20T19:37:28.188+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:37:28.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:37:28.193+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:37:28.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:37:28.782+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:37:28.844+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:37:28.869+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:37:28.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:37:28.881+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:37:28.880+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:37:28.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.723 seconds
[2025-09-20T19:37:59.611+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:37:59.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:37:59.615+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:37:59.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:38:00.234+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:38:00.308+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:38:00.334+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:38:00.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:38:00.346+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:38:00.346+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:38:00.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.764 seconds
[2025-09-20T19:38:31.081+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:38:31.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:38:31.085+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:38:31.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:38:31.678+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:38:31.742+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:38:31.768+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:38:31.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:38:31.779+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:38:31.779+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:38:31.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.726 seconds
[2025-09-20T19:39:02.413+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:02.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:39:02.417+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:02.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:03.043+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:39:03.102+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:03.128+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:03.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:39:03.140+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:03.139+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:39:03.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.754 seconds
[2025-09-20T19:39:22.536+0000] {processor.py:186} INFO - Started process (PID=24) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:22.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:39:22.541+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:22.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:23.128+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:39:23.185+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:23.210+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:23.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:39:23.221+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:23.221+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:39:23.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.711 seconds
[2025-09-20T19:39:53.957+0000] {processor.py:186} INFO - Started process (PID=28) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:53.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:39:53.961+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:53.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:54.544+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:39:54.611+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:39:54.640+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:54.640+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:39:54.651+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:39:54.650+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:39:54.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.724 seconds
[2025-09-20T19:40:25.354+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:40:25.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:40:25.358+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:40:25.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:40:25.910+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:40:25.971+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:40:25.994+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:40:25.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:40:26.006+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:40:26.006+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:40:26.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.677 seconds
[2025-09-20T19:40:56.759+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:40:56.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:40:56.763+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:40:56.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:40:57.322+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:40:57.377+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:40:57.402+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:40:57.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:40:57.414+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:40:57.414+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:40:57.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.688 seconds
[2025-09-20T19:41:28.160+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:41:28.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:41:28.164+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:41:28.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:41:28.879+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:41:28.948+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:41:28.973+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:41:28.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:41:28.984+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:41:28.984+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:41:29.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.851 seconds
[2025-09-20T19:41:59.581+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:41:59.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:41:59.585+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:41:59.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:42:00.259+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:42:00.329+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:42:00.355+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:42:00.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:42:00.367+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:42:00.367+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:42:00.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.816 seconds
[2025-09-20T19:42:31.065+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:42:31.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:42:31.070+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:42:31.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:42:31.702+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:42:31.758+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:42:31.785+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:42:31.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:42:31.797+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:42:31.797+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:42:31.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.761 seconds
[2025-09-20T19:43:02.466+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:43:02.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:43:02.470+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:43:02.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:43:03.039+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:43:03.095+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:43:03.121+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:43:03.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:43:03.134+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:43:03.133+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:43:03.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.706 seconds
[2025-09-20T19:43:33.854+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:43:33.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:43:33.858+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:43:33.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:43:34.461+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:43:34.527+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:43:34.555+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:43:34.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:43:34.567+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:43:34.567+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:43:34.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.749 seconds
[2025-09-20T19:44:05.251+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:44:05.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:44:05.256+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:44:05.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:44:05.863+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:44:05.949+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:44:05.976+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:44:05.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:44:05.990+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:44:05.989+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:44:06.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.767 seconds
[2025-09-20T19:44:36.807+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:44:36.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:44:36.811+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:44:36.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:44:37.403+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:44:37.464+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:44:37.490+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:44:37.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:44:37.502+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:44:37.502+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:44:37.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.724 seconds
[2025-09-20T19:45:08.220+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:45:08.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:45:08.224+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:45:08.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:45:08.864+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:45:08.929+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:45:08.955+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:45:08.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:45:08.967+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:45:08.966+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:45:08.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.775 seconds
[2025-09-20T19:45:39.632+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:45:39.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:45:39.636+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:45:39.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:45:40.205+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:45:40.263+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:45:40.288+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:45:40.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:45:40.299+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:45:40.299+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:45:40.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.696 seconds
[2025-09-20T19:46:11.049+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:46:11.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:46:11.054+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:46:11.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:46:11.660+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:46:11.725+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:46:11.751+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:46:11.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:46:11.764+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:46:11.764+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:46:11.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.747 seconds
[2025-09-20T19:46:42.441+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:46:42.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:46:42.445+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:46:42.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:46:43.013+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:46:43.080+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:46:43.106+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:46:43.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:46:43.118+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:46:43.117+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:46:43.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.708 seconds
[2025-09-20T19:47:13.836+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:47:13.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:47:13.840+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:47:13.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:47:14.470+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:47:14.548+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:47:14.574+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:47:14.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:47:14.586+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:47:14.586+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:47:14.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.778 seconds
[2025-09-20T19:47:45.254+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:47:45.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:47:45.258+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:47:45.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:47:45.882+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:47:45.950+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:47:45.982+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:47:45.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:47:46.002+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:47:46.002+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:47:46.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.784 seconds
[2025-09-20T19:48:16.662+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:48:16.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:48:16.666+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:48:16.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:48:17.279+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:48:17.348+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:48:17.375+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:48:17.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:48:17.387+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:48:17.386+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:48:17.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.759 seconds
[2025-09-20T19:48:48.104+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:48:48.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:48:48.108+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:48:48.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:48:48.763+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:48:48.818+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:48:48.847+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:48:48.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:48:48.857+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:48:48.857+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:48:48.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.783 seconds
[2025-09-20T19:49:19.530+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:49:19.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:49:19.534+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:49:19.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:49:20.176+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:49:20.235+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:49:20.262+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:49:20.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:49:20.276+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:49:20.276+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:49:20.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.783 seconds
[2025-09-20T19:49:50.989+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:49:50.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:49:50.993+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:49:50.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:49:51.643+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:49:51.715+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:49:51.741+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:49:51.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:49:51.752+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:49:51.752+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:49:51.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.791 seconds
[2025-09-20T19:50:22.402+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:50:22.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:50:22.406+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:50:22.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:50:23.013+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:50:23.079+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:50:23.105+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:50:23.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:50:23.116+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:50:23.116+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:50:23.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.750 seconds
[2025-09-20T19:50:53.873+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:50:53.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:50:53.877+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:50:53.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:50:54.502+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:50:54.563+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:50:54.590+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:50:54.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:50:54.602+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:50:54.602+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:50:54.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.763 seconds
[2025-09-20T19:51:25.273+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:51:25.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:51:25.277+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:51:25.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:51:25.856+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:51:25.927+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:51:25.953+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:51:25.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:51:25.965+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:51:25.964+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:51:25.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.719 seconds
[2025-09-20T19:51:56.689+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:51:56.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:51:56.693+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:51:56.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:51:57.270+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:51:57.331+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:51:57.357+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:51:57.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:51:57.370+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:51:57.369+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:51:57.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.709 seconds
[2025-09-20T19:52:28.193+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:52:28.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:52:28.197+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:52:28.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:52:28.833+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:52:28.909+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:52:28.933+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:52:28.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:52:28.944+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:52:28.944+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:52:28.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.774 seconds
[2025-09-20T19:52:59.500+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:52:59.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:52:59.504+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:52:59.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:53:00.087+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:53:00.150+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:53:00.173+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:53:00.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:53:00.184+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:53:00.184+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:53:00.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.711 seconds
[2025-09-20T19:53:30.937+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:53:30.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:53:30.941+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:53:30.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:53:31.526+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:53:31.589+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:53:31.616+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:53:31.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:53:31.626+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:53:31.626+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:53:31.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.720 seconds
[2025-09-20T19:54:02.340+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:54:02.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:54:02.344+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:54:02.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:54:02.956+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:54:03.011+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:54:03.038+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:54:03.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:54:03.049+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:54:03.049+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:54:03.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.739 seconds
[2025-09-20T19:54:33.762+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:54:33.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:54:33.767+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:54:33.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:54:34.484+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:54:34.540+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:54:34.567+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:54:34.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:54:34.578+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:54:34.577+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:54:34.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.846 seconds
[2025-09-20T19:55:05.238+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:55:05.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:55:05.242+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:55:05.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:55:05.864+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:55:05.928+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:55:05.953+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:55:05.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:55:05.966+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:55:05.965+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:55:05.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T19:55:36.680+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:55:36.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:55:36.685+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:55:36.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:55:37.304+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:55:37.369+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:55:37.398+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:55:37.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:55:37.409+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:55:37.409+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:55:37.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T19:56:08.089+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:56:08.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:56:08.093+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:56:08.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:56:08.684+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:56:08.750+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:56:08.778+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:56:08.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:56:08.790+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:56:08.790+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:56:08.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.727 seconds
[2025-09-20T19:56:39.495+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:56:39.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:56:39.499+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:56:39.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:56:40.162+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:56:40.219+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:56:40.248+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:56:40.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:56:40.260+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:56:40.260+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:56:40.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.793 seconds
[2025-09-20T19:57:10.894+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:57:10.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:57:10.898+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:57:10.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:57:11.510+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:57:11.571+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:57:11.595+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:57:11.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:57:11.610+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:57:11.610+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:57:11.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.748 seconds
[2025-09-20T19:57:42.296+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:57:42.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:57:42.301+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:57:42.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:57:42.899+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:57:42.954+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:57:42.979+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:57:42.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:57:42.991+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:57:42.991+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:57:43.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.723 seconds
[2025-09-20T19:58:13.706+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:58:13.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:58:13.709+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:58:13.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:58:14.304+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:58:14.365+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:58:14.390+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:58:14.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:58:14.402+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:58:14.402+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:58:14.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.727 seconds
[2025-09-20T19:58:45.110+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:58:45.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:58:45.114+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:58:45.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:58:45.719+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:58:45.775+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:58:45.800+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:58:45.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:58:45.837+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:58:45.836+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:58:45.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.756 seconds
[2025-09-20T19:59:16.522+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:59:16.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:59:16.525+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:59:16.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:59:17.103+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:59:17.157+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:59:17.182+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:59:17.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:59:17.193+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:59:17.193+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:59:17.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.699 seconds
[2025-09-20T19:59:47.939+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:59:47.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T19:59:47.943+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:59:47.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:59:48.552+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T19:59:48.613+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T19:59:48.638+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:59:48.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T19:59:48.649+0000] {logging_mixin.py:190} INFO - [2025-09-20T19:59:48.649+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T19:59:48.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.738 seconds
[2025-09-20T20:00:19.354+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:00:19.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:00:19.358+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:00:19.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:00:19.988+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:00:20.055+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:00:20.086+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:00:20.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:00:20.098+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:00:20.098+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:00:20.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.783 seconds
[2025-09-20T20:00:50.724+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:00:50.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:00:50.728+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:00:50.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:00:51.411+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:00:51.474+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:00:51.500+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:00:51.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:00:51.514+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:00:51.513+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:00:51.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.821 seconds
[2025-09-20T20:01:22.126+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:01:22.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:01:22.130+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:01:22.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:01:22.733+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:01:22.796+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:01:22.824+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:01:22.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:01:22.836+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:01:22.836+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:01:22.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.738 seconds
[2025-09-20T20:01:53.531+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:01:53.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:01:53.535+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:01:53.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:01:54.141+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:01:54.196+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:01:54.221+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:01:54.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:01:54.233+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:01:54.233+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:01:54.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.731 seconds
[2025-09-20T20:02:24.939+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:02:24.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:02:24.943+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:02:24.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:02:25.538+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:02:25.602+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:02:25.627+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:02:25.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:02:25.638+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:02:25.638+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:02:25.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.729 seconds
[2025-09-20T20:02:56.342+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:02:56.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:02:56.348+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:02:56.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:02:57.083+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:02:57.165+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:02:57.192+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:02:57.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:02:57.204+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:02:57.204+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:02:57.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.890 seconds
[2025-09-20T20:03:27.554+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:03:27.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:03:27.559+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:03:27.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:03:28.159+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:03:28.215+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:03:28.242+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:03:28.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:03:28.255+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:03:28.255+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:03:28.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.730 seconds
[2025-09-20T20:03:58.961+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:03:58.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:03:58.964+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:03:58.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:03:59.644+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:03:59.705+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:03:59.730+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:03:59.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:03:59.743+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:03:59.743+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:03:59.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.808 seconds
[2025-09-20T20:04:30.446+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:04:30.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:04:30.450+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:04:30.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:04:31.036+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:04:31.093+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:04:31.118+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:04:31.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:04:31.129+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:04:31.129+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:04:31.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.710 seconds
[2025-09-20T20:05:01.785+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:05:01.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:05:01.789+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:05:01.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:05:02.436+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:05:02.497+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:05:02.527+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:05:02.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:05:02.557+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:05:02.557+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:05:02.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.803 seconds
[2025-09-20T20:05:33.187+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:05:33.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:05:33.191+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:05:33.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:05:33.795+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:05:33.854+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:05:33.881+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:05:33.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:05:33.892+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:05:33.892+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:05:33.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.734 seconds
[2025-09-20T20:06:04.616+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:06:04.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:06:04.620+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:06:04.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:06:05.243+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:06:05.303+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:06:05.328+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:06:05.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:06:05.341+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:06:05.341+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:06:05.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.756 seconds
[2025-09-20T20:06:36.012+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:06:36.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:06:36.017+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:06:36.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:06:36.644+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:06:36.705+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:06:36.731+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:06:36.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:06:36.744+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:06:36.744+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:06:36.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.760 seconds
[2025-09-20T20:07:07.412+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:07:07.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:07:07.417+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:07:07.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:07:08.073+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:07:08.137+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:07:08.164+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:07:08.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:07:08.176+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:07:08.176+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:07:08.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.792 seconds
[2025-09-20T20:07:38.821+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:07:38.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:07:38.825+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:07:38.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:07:39.439+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:07:39.497+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:07:39.535+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:07:39.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:07:39.553+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:07:39.553+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:07:39.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.770 seconds
[2025-09-20T20:08:10.233+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:08:10.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:08:10.237+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:08:10.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:08:10.842+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:08:10.902+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:08:10.929+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:08:10.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:08:10.941+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:08:10.941+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:08:10.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.736 seconds
[2025-09-20T20:08:41.638+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:08:41.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:08:41.642+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:08:41.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:08:42.316+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:08:42.378+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:08:42.404+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:08:42.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:08:42.416+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:08:42.415+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:08:42.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.808 seconds
[2025-09-20T20:09:13.037+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:09:13.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:09:13.041+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:09:13.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:09:13.648+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:09:13.709+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:09:13.735+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:09:13.735+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:09:13.748+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:09:13.748+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:09:13.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.739 seconds
[2025-09-20T20:09:44.443+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:09:44.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:09:44.447+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:09:44.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:09:45.060+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:09:45.118+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:09:45.144+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:09:45.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:09:45.156+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:09:45.156+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:09:45.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.749 seconds
[2025-09-20T20:10:15.898+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:10:15.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:10:15.902+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:10:15.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:10:16.556+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:10:16.656+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:10:16.682+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:10:16.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:10:16.694+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:10:16.694+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:10:16.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.828 seconds
[2025-09-20T20:10:47.306+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:10:47.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:10:47.310+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:10:47.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:10:47.940+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:10:48.012+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:10:48.049+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:10:48.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:10:48.061+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:10:48.061+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:10:48.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.783 seconds
[2025-09-20T20:11:18.738+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:11:18.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:11:18.742+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:11:18.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:11:19.357+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:11:19.418+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:11:19.444+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:11:19.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:11:19.456+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:11:19.456+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:11:19.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.748 seconds
[2025-09-20T20:11:50.149+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:11:50.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:11:50.153+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:11:50.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:11:50.770+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:11:50.862+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:11:50.888+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:11:50.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:11:50.902+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:11:50.902+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:11:50.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.790 seconds
[2025-09-20T20:12:21.559+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:12:21.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:12:21.564+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:12:21.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:12:22.159+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:12:22.222+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:12:22.249+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:12:22.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:12:22.262+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:12:22.261+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:12:22.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.732 seconds
[2025-09-20T20:12:52.974+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:12:52.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:12:52.978+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:12:52.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:12:53.571+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:12:53.638+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:12:53.665+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:12:53.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:12:53.677+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:12:53.676+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:12:53.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.732 seconds
[2025-09-20T20:13:24.391+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:13:24.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:13:24.396+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:13:24.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:13:24.974+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:13:25.030+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:13:25.056+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:13:25.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:13:25.068+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:13:25.068+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:13:25.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.707 seconds
[2025-09-20T20:13:55.784+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:13:55.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:13:55.788+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:13:55.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:13:56.389+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:13:56.452+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:13:56.478+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:13:56.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:13:56.489+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:13:56.489+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:13:56.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.733 seconds
[2025-09-20T20:14:27.227+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:14:27.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:14:27.231+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:14:27.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:14:27.841+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:14:27.903+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:14:27.918+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:14:27.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:14:27.931+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:14:27.931+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:14:27.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.742 seconds
[2025-09-20T20:14:58.392+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:14:58.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:14:58.396+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:14:58.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:14:58.981+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:14:59.054+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:14:59.150+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:14:59.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:14:59.161+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:14:59.160+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:14:59.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.796 seconds
[2025-09-20T20:15:29.779+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:15:29.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:15:29.783+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:15:29.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:15:30.394+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:15:30.451+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:15:30.475+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:15:30.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:15:30.486+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:15:30.486+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:15:30.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.742 seconds
[2025-09-20T20:16:00.692+0000] {processor.py:186} INFO - Started process (PID=298) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:16:00.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:16:00.696+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:16:00.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:16:01.304+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:16:01.369+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:16:01.384+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:16:01.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:16:01.395+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:16:01.394+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:16:01.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.729 seconds
[2025-09-20T20:16:31.514+0000] {processor.py:186} INFO - Started process (PID=303) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:16:31.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:16:31.518+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:16:31.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:16:32.069+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:16:32.135+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:16:32.225+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:16:32.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:16:32.234+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:16:32.234+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:16:32.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.747 seconds
[2025-09-20T20:17:02.354+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:17:02.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:17:02.358+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:17:02.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:17:02.956+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:17:03.011+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:17:03.035+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:17:03.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:17:03.046+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:17:03.046+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:17:03.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.729 seconds
[2025-09-20T20:17:33.221+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:17:33.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:17:33.225+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:17:33.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:17:33.777+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:17:33.839+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:17:33.853+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:17:33.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:17:33.863+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:17:33.863+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:17:33.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.669 seconds
[2025-09-20T20:18:04.013+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:18:04.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:18:04.017+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:18:04.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:18:04.659+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:18:04.717+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:18:04.810+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:18:04.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:18:04.820+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:18:04.820+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:18:04.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.843 seconds
[2025-09-20T20:18:35.054+0000] {processor.py:186} INFO - Started process (PID=323) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:18:35.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:18:35.058+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:18:35.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:18:35.638+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:18:35.696+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:18:35.722+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:18:35.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:18:35.734+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:18:35.734+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:18:35.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.717 seconds
[2025-09-20T20:19:06.513+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:19:06.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:19:06.517+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:19:06.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:19:07.111+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:19:07.172+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:19:07.189+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:19:07.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:19:07.200+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:19:07.200+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:19:07.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.717 seconds
[2025-09-20T20:19:38.031+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:19:38.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:19:38.035+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:19:38.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:19:38.612+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:19:38.675+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:19:38.766+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:19:38.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:19:38.775+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:19:38.775+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:19:38.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.770 seconds
[2025-09-20T20:20:09.304+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:20:09.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:20:09.308+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:20:09.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:20:09.857+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:20:09.914+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:20:09.938+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:20:09.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:20:09.950+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:20:09.950+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:20:09.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.675 seconds
[2025-09-20T20:20:40.166+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:20:40.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:20:40.171+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:20:40.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:20:40.795+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:20:40.869+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:20:40.885+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:20:40.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:20:40.901+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:20:40.901+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:20:40.920+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.763 seconds
[2025-09-20T20:21:11.037+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:21:11.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:21:11.041+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:21:11.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:21:11.610+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:21:11.670+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:21:11.760+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:21:11.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:21:11.769+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:21:11.769+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:21:11.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T20:21:41.887+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:21:41.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:21:41.892+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:21:41.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:21:42.476+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:21:42.535+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:21:42.559+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:21:42.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:21:42.570+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:21:42.570+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:21:42.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.712 seconds
[2025-09-20T20:22:12.800+0000] {processor.py:186} INFO - Started process (PID=358) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:22:12.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:22:12.804+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:22:12.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:22:13.412+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:22:13.476+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:22:13.491+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:22:13.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:22:13.502+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:22:13.502+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:22:13.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.729 seconds
[2025-09-20T20:22:44.126+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:22:44.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:22:44.130+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:22:44.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:22:44.759+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:22:44.828+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:22:44.948+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:22:44.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:22:44.958+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:22:44.958+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:22:44.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.871 seconds
[2025-09-20T20:23:15.604+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:23:15.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:23:15.618+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:23:15.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:23:16.248+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:23:16.307+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:23:16.331+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:23:16.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:23:16.342+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:23:16.342+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:23:16.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.773 seconds
[2025-09-20T20:23:47.086+0000] {processor.py:186} INFO - Started process (PID=373) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:23:47.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:23:47.090+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:23:47.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:23:47.655+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:23:47.720+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:23:47.735+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:23:47.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:23:47.746+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:23:47.746+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:23:47.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.689 seconds
[2025-09-20T20:24:17.834+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:24:17.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:24:17.838+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:24:17.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:24:18.460+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:24:18.516+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:24:18.612+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:24:18.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:24:18.622+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:24:18.621+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:24:18.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.816 seconds
[2025-09-20T20:24:48.791+0000] {processor.py:186} INFO - Started process (PID=383) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:24:48.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:24:48.795+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:24:48.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:24:49.373+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:24:49.430+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:24:49.454+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:24:49.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:24:49.464+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:24:49.464+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:24:49.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.708 seconds
[2025-09-20T20:25:02.430+0000] {processor.py:186} INFO - Started process (PID=387) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:25:02.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:25:02.437+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:25:02.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:25:03.161+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:25:03.220+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:25:03.255+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:25:03.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:25:03.270+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:25:03.270+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:25:03.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.879 seconds
[2025-09-20T20:25:33.761+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:25:33.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:25:33.766+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:25:33.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:25:34.393+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:25:34.441+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:25:34.470+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:25:34.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:25:34.483+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:25:34.483+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:25:34.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.751 seconds
[2025-09-20T20:26:04.940+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:26:04.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:26:04.945+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:26:04.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:26:05.590+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:26:05.627+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:26:05.654+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:26:05.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:26:05.667+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:26:05.666+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:26:05.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.771 seconds
[2025-09-20T20:26:36.361+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:26:36.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:26:36.366+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:26:36.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:26:37.029+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:26:37.092+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:26:37.122+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:26:37.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:26:37.136+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:26:37.136+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:26:37.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.807 seconds
[2025-09-20T20:27:07.327+0000] {processor.py:186} INFO - Started process (PID=441) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:27:07.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:27:07.331+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:27:07.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:27:07.884+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:27:07.942+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:27:07.966+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:27:07.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:27:07.976+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:27:07.976+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:27:08.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.684 seconds
[2025-09-20T20:27:38.800+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:27:38.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:27:38.805+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:27:38.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:27:39.376+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:27:39.435+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:27:39.459+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:27:39.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:27:39.470+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:27:39.469+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:27:39.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.698 seconds
[2025-09-20T20:28:10.006+0000] {processor.py:186} INFO - Started process (PID=451) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:28:10.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:28:10.010+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:28:10.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:28:10.590+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:28:10.686+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:28:10.715+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:28:10.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:28:10.726+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:28:10.725+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:28:10.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.745 seconds
[2025-09-20T20:28:41.449+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:28:41.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:28:41.452+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:28:41.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:28:42.042+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:28:42.100+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:28:42.127+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:28:42.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:28:42.140+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:28:42.140+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:28:42.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.720 seconds
[2025-09-20T20:29:12.664+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:29:12.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:29:12.669+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:29:12.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:29:13.269+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:29:13.316+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:29:13.345+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:29:13.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:29:13.357+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:29:13.357+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:29:13.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.726 seconds
[2025-09-20T20:29:44.145+0000] {processor.py:186} INFO - Started process (PID=467) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:29:44.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:29:44.149+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:29:44.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:29:44.712+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:29:44.749+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:29:44.773+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:29:44.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:29:44.783+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:29:44.783+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:29:44.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.677 seconds
[2025-09-20T20:30:15.580+0000] {processor.py:186} INFO - Started process (PID=472) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:30:15.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:30:15.584+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:30:15.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:30:16.243+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:30:16.290+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:30:16.316+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:30:16.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:30:16.328+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:30:16.328+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:30:16.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.780 seconds
[2025-09-20T20:30:47.038+0000] {processor.py:186} INFO - Started process (PID=477) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:30:47.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:30:47.042+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:30:47.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:30:47.642+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:30:47.684+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:30:47.710+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:30:47.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:30:47.722+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:30:47.722+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:30:47.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.722 seconds
[2025-09-20T20:31:18.473+0000] {processor.py:186} INFO - Started process (PID=482) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:31:18.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:31:18.478+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:31:18.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:31:19.128+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:31:19.199+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:31:19.226+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:31:19.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:31:19.240+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:31:19.239+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:31:19.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.799 seconds
[2025-09-20T20:31:49.659+0000] {processor.py:186} INFO - Started process (PID=487) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:31:49.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:31:49.663+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:31:49.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:31:50.281+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:31:50.338+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:31:50.369+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:31:50.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:31:50.384+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:31:50.384+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:31:50.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.764 seconds
[2025-09-20T20:32:20.801+0000] {processor.py:186} INFO - Started process (PID=492) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:32:20.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:32:20.807+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:32:20.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:32:21.417+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:32:21.454+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:32:21.479+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:32:21.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:32:21.491+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:32:21.490+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:32:21.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.730 seconds
[2025-09-20T20:32:52.221+0000] {processor.py:186} INFO - Started process (PID=497) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:32:52.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:32:52.224+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:32:52.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:32:52.840+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:32:52.888+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:32:52.913+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:32:52.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:32:52.924+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:32:52.924+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:32:52.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.732 seconds
[2025-09-20T20:33:23.701+0000] {processor.py:186} INFO - Started process (PID=502) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:33:23.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:33:23.706+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:33:23.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:33:24.350+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:33:24.412+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:33:24.438+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:33:24.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:33:24.464+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:33:24.464+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:33:24.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.789 seconds
[2025-09-20T20:33:54.830+0000] {processor.py:186} INFO - Started process (PID=507) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:33:54.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:33:54.834+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:33:54.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:33:55.453+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:33:55.469+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:33:55.466+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/clean_users_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/clean_users_dag.py", line 10, in <module>
    from src.etl.transform import transform_users_from_lake
  File "/opt/airflow/src/etl/transform.py", line 29
    
    ^
IndentationError: expected an indented block after function definition on line 28
[2025-09-20T20:33:55.471+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:33:55.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.675 seconds
[2025-09-20T20:34:26.308+0000] {processor.py:186} INFO - Started process (PID=512) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:34:26.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:34:26.312+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:34:26.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:34:26.958+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:34:27.009+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:34:27.035+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:34:27.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:34:27.047+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:34:27.047+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:34:27.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.779 seconds
[2025-09-20T20:34:57.445+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:34:57.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:34:57.449+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:34:57.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:34:58.150+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:34:58.214+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:34:58.242+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:34:58.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:34:58.256+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:34:58.255+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:34:58.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.843 seconds
[2025-09-20T20:35:28.627+0000] {processor.py:186} INFO - Started process (PID=522) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:35:28.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:35:28.631+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:35:28.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:35:29.287+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:35:29.324+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:35:29.351+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:35:29.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:35:29.363+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:35:29.363+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:35:29.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.766 seconds
[2025-09-20T20:36:00.150+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:36:00.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:36:00.155+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:36:00.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:36:00.859+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:36:00.929+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:36:00.982+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:36:00.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:36:01.005+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:36:01.005+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:36:01.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.895 seconds
[2025-09-20T20:36:31.383+0000] {processor.py:186} INFO - Started process (PID=533) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:36:31.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:36:31.388+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:36:31.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:36:32.032+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:36:32.097+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:36:32.126+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:36:32.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:36:32.148+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:36:32.148+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:36:32.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.797 seconds
[2025-09-20T20:37:02.562+0000] {processor.py:186} INFO - Started process (PID=571) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:37:02.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:37:02.566+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:37:02.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:37:03.133+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:37:03.193+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:37:03.218+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:37:03.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:37:03.230+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:37:03.230+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:37:03.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.697 seconds
[2025-09-20T20:37:33.917+0000] {processor.py:186} INFO - Started process (PID=576) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:37:33.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:37:33.921+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:37:33.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:37:34.520+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:37:34.585+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:37:34.610+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:37:34.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:37:34.621+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:37:34.621+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:37:34.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.731 seconds
[2025-09-20T20:38:04.766+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:38:04.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:38:04.770+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:38:04.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:38:05.355+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:38:05.417+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:38:05.442+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:38:05.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:38:05.453+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:38:05.453+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:38:05.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.725 seconds
[2025-09-20T20:38:35.656+0000] {processor.py:186} INFO - Started process (PID=586) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:38:35.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:38:35.660+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:38:35.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:38:36.299+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:38:36.363+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:38:36.394+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:38:36.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:38:36.406+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:38:36.406+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:38:36.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.780 seconds
[2025-09-20T20:39:07.086+0000] {processor.py:186} INFO - Started process (PID=591) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:39:07.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:39:07.090+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:39:07.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:39:07.715+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:39:07.771+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:39:07.800+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:39:07.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:39:07.812+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:39:07.812+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:39:07.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.762 seconds
[2025-09-20T20:39:38.668+0000] {processor.py:186} INFO - Started process (PID=596) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:39:38.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:39:38.673+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:39:38.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:39:39.286+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:39:39.357+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:39:39.383+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:39:39.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:39:39.396+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:39:39.395+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:39:39.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T20:40:10.081+0000] {processor.py:186} INFO - Started process (PID=601) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:40:10.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:40:10.085+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:40:10.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:40:10.695+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:40:10.752+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:40:10.777+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:40:10.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:40:10.789+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:40:10.788+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:40:10.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.735 seconds
[2025-09-20T20:40:41.509+0000] {processor.py:186} INFO - Started process (PID=606) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:40:41.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:40:41.513+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:40:41.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:40:42.125+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:40:42.193+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:40:42.219+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:40:42.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:40:42.230+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:40:42.230+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:40:42.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.748 seconds
[2025-09-20T20:41:12.305+0000] {processor.py:186} INFO - Started process (PID=611) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:41:12.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:41:12.310+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:41:12.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:41:12.936+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:41:13.000+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:41:13.027+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:41:13.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:41:13.039+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:41:13.039+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:41:13.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.765 seconds
[2025-09-20T20:41:43.579+0000] {processor.py:186} INFO - Started process (PID=617) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:41:43.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:41:43.583+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:41:43.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:41:44.271+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:41:44.329+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:41:44.355+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:41:44.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:41:44.367+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:41:44.367+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:41:44.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.819 seconds
[2025-09-20T20:42:15.042+0000] {processor.py:186} INFO - Started process (PID=622) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:42:15.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:42:15.046+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:42:15.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:42:15.655+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:42:15.708+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:42:15.734+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:42:15.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:42:15.746+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:42:15.746+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:42:15.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.733 seconds
[2025-09-20T20:42:46.468+0000] {processor.py:186} INFO - Started process (PID=627) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:42:46.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:42:46.472+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:42:46.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:42:47.078+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:42:47.137+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:42:47.163+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:42:47.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:42:47.175+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:42:47.175+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:42:47.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.742 seconds
[2025-09-20T20:43:17.728+0000] {processor.py:186} INFO - Started process (PID=632) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:43:17.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:43:17.735+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:43:17.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:43:18.395+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:43:18.457+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:43:18.483+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:43:18.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:43:18.495+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:43:18.495+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:43:18.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.796 seconds
[2025-09-20T20:43:49.200+0000] {processor.py:186} INFO - Started process (PID=670) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:43:49.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:43:49.204+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:43:49.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:43:49.765+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:43:49.824+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:43:49.848+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:43:49.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:43:49.858+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:43:49.858+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:43:49.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.693 seconds
[2025-09-20T20:44:20.643+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:44:20.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:44:20.647+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:44:20.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:44:21.266+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:44:21.352+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:44:21.394+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:44:21.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:44:21.419+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:44:21.419+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:44:21.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.804 seconds
[2025-09-20T20:44:51.920+0000] {processor.py:186} INFO - Started process (PID=680) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:44:51.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:44:51.925+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:44:51.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:44:52.514+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:44:52.573+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:44:52.599+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:44:52.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:44:52.611+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:44:52.611+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:44:52.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.727 seconds
[2025-09-20T20:45:23.376+0000] {processor.py:186} INFO - Started process (PID=685) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:45:23.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:45:23.381+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:45:23.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:45:23.980+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:45:24.041+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:45:24.067+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:45:24.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:45:24.080+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:45:24.080+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:45:24.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.742 seconds
[2025-09-20T20:45:54.820+0000] {processor.py:186} INFO - Started process (PID=690) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:45:54.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:45:54.823+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:45:54.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:45:55.458+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:45:55.517+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:45:55.546+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:45:55.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:45:55.560+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:45:55.560+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:45:55.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.770 seconds
[2025-09-20T20:46:26.270+0000] {processor.py:186} INFO - Started process (PID=695) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:46:26.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:46:26.275+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:46:26.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:46:26.913+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:46:26.990+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:46:27.017+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:46:27.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:46:27.029+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:46:27.029+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:46:27.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.786 seconds
[2025-09-20T20:46:57.648+0000] {processor.py:186} INFO - Started process (PID=712) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:46:57.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:46:57.654+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:46:57.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:46:58.366+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:46:58.420+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:46:58.447+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:46:58.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:46:58.459+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:46:58.458+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:46:58.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.845 seconds
[2025-09-20T20:47:29.091+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:47:29.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:47:29.095+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:47:29.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:47:29.686+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:47:29.746+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:47:29.772+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:47:29.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:47:29.785+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:47:29.785+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:47:29.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.726 seconds
[2025-09-20T20:48:00.548+0000] {processor.py:186} INFO - Started process (PID=743) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:48:00.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:48:00.551+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:48:00.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:48:01.139+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:48:01.204+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:48:01.228+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:48:01.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:48:01.239+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:48:01.239+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:48:01.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.720 seconds
[2025-09-20T20:48:31.799+0000] {processor.py:186} INFO - Started process (PID=748) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:48:31.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:48:31.803+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:48:31.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:48:32.362+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:48:32.425+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:48:32.450+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:48:32.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:48:32.460+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:48:32.460+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:48:32.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.698 seconds
[2025-09-20T20:49:03.267+0000] {processor.py:186} INFO - Started process (PID=753) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:49:03.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:49:03.271+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:49:03.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:49:03.858+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:49:03.917+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:49:03.941+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:49:03.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:49:03.951+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:49:03.951+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:49:03.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.711 seconds
[2025-09-20T20:49:34.515+0000] {processor.py:186} INFO - Started process (PID=758) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:49:34.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:49:34.520+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:49:34.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:49:35.073+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:49:35.131+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:49:35.155+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:49:35.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:49:35.165+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:49:35.165+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:49:35.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.676 seconds
[2025-09-20T20:50:05.891+0000] {processor.py:186} INFO - Started process (PID=786) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:50:05.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:50:05.895+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:50:05.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:50:06.550+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:50:06.611+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:50:06.636+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:50:06.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:50:06.652+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:50:06.652+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:50:06.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.793 seconds
[2025-09-20T20:50:37.320+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:50:37.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:50:37.324+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:50:37.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:50:37.904+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:50:37.969+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:50:37.993+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:50:37.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:50:38.005+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:50:38.004+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:50:38.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.712 seconds
[2025-09-20T20:51:08.778+0000] {processor.py:186} INFO - Started process (PID=806) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:51:08.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:51:08.783+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:51:08.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:51:09.348+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:51:09.412+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:51:09.437+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:51:09.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:51:09.447+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:51:09.447+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:51:09.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.697 seconds
[2025-09-20T20:51:40.139+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:51:40.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:51:40.144+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:51:40.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:51:40.699+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:51:40.763+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:51:40.787+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:51:40.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:51:40.798+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:51:40.798+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:51:40.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.686 seconds
[2025-09-20T20:52:11.671+0000] {processor.py:186} INFO - Started process (PID=816) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:52:11.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:52:11.678+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:52:11.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:52:12.395+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:52:12.455+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:52:12.481+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:52:12.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:52:12.493+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:52:12.492+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:52:12.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.865 seconds
[2025-09-20T20:52:42.979+0000] {processor.py:186} INFO - Started process (PID=821) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:52:42.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:52:42.984+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:52:42.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:52:43.556+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:52:43.608+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:52:43.634+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:52:43.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:52:43.646+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:52:43.646+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:52:43.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.699 seconds
[2025-09-20T20:53:14.317+0000] {processor.py:186} INFO - Started process (PID=826) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:53:14.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:53:14.321+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:53:14.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:53:14.922+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:53:14.980+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:53:15.010+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:53:15.009+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:53:15.022+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:53:15.022+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:53:15.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.741 seconds
[2025-09-20T20:53:45.221+0000] {processor.py:186} INFO - Started process (PID=831) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:53:45.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:53:45.225+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:53:45.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:53:45.819+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:53:45.880+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:53:45.906+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:53:45.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:53:45.918+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:53:45.918+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:53:45.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.735 seconds
[2025-09-20T20:54:16.074+0000] {processor.py:186} INFO - Started process (PID=836) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:54:16.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:54:16.078+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:54:16.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:54:16.651+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:54:16.710+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:54:16.736+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:54:16.735+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:54:16.747+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:54:16.747+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:54:16.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.701 seconds
[2025-09-20T20:54:46.879+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:54:46.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:54:46.883+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:54:46.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:54:47.474+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:54:47.540+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:54:47.566+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:54:47.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:54:47.578+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:54:47.578+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:54:47.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.727 seconds
[2025-09-20T20:55:17.707+0000] {processor.py:186} INFO - Started process (PID=853) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:55:17.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:55:17.711+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:55:17.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:55:18.328+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:55:18.390+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:55:18.416+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:55:18.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:55:18.427+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:55:18.427+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:55:18.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.749 seconds
[2025-09-20T20:55:48.542+0000] {processor.py:186} INFO - Started process (PID=899) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:55:48.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:55:48.545+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:55:48.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:55:49.143+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:55:49.203+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:55:49.229+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:55:49.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:55:49.240+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:55:49.240+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:55:49.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.726 seconds
[2025-09-20T20:56:19.365+0000] {processor.py:186} INFO - Started process (PID=913) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:56:19.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:56:19.369+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:56:19.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:56:19.938+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:56:20.007+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:56:20.031+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:56:20.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:56:20.042+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:56:20.042+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:56:20.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.706 seconds
[2025-09-20T20:56:50.288+0000] {processor.py:186} INFO - Started process (PID=951) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:56:50.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:56:50.292+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:56:50.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:56:50.865+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:56:50.926+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:56:50.954+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:56:50.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:56:50.966+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:56:50.965+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:56:50.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.710 seconds
[2025-09-20T20:57:21.112+0000] {processor.py:186} INFO - Started process (PID=956) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:57:21.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:57:21.117+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:57:21.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:57:21.695+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:57:21.753+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:57:21.777+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:57:21.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:57:21.788+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:57:21.788+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:57:21.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.702 seconds
[2025-09-20T20:57:51.977+0000] {processor.py:186} INFO - Started process (PID=961) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:57:51.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:57:51.981+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:57:51.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:57:52.553+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:57:52.621+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:57:52.644+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:57:52.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:57:52.654+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:57:52.654+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:57:52.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.708 seconds
[2025-09-20T20:58:22.770+0000] {processor.py:186} INFO - Started process (PID=966) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:58:22.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:58:22.774+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:58:22.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:58:23.349+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:58:23.407+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:58:23.432+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:58:23.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:58:23.444+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:58:23.444+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:58:23.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.711 seconds
[2025-09-20T20:58:53.605+0000] {processor.py:186} INFO - Started process (PID=971) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:58:53.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:58:53.610+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:58:53.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:58:54.240+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:58:54.302+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:58:54.327+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:58:54.327+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:58:54.340+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:58:54.340+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:58:54.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.773 seconds
[2025-09-20T20:59:24.688+0000] {processor.py:186} INFO - Started process (PID=976) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:59:24.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:59:24.693+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:59:24.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:59:25.261+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:59:25.320+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:59:25.346+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:59:25.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:59:25.357+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:59:25.357+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:59:25.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.699 seconds
[2025-09-20T20:59:55.994+0000] {processor.py:186} INFO - Started process (PID=981) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:59:55.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T20:59:55.999+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:59:55.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:59:56.623+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T20:59:56.689+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T20:59:56.714+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:59:56.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T20:59:56.725+0000] {logging_mixin.py:190} INFO - [2025-09-20T20:59:56.725+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T20:59:56.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.760 seconds
[2025-09-20T21:00:26.837+0000] {processor.py:186} INFO - Started process (PID=987) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:00:26.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:00:26.841+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:00:26.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:00:27.465+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:00:27.521+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:00:27.546+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:00:27.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:00:27.556+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:00:27.556+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:00:27.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.747 seconds
[2025-09-20T21:00:58.264+0000] {processor.py:186} INFO - Started process (PID=992) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:00:58.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:00:58.269+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:00:58.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:00:59.107+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:00:59.164+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:00:59.195+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:00:59.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:00:59.207+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:00:59.207+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:00:59.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.984 seconds
[2025-09-20T21:01:29.617+0000] {processor.py:186} INFO - Started process (PID=997) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:01:29.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:01:29.622+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:01:29.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:01:30.209+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:01:30.262+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:01:30.287+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:01:30.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:01:30.300+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:01:30.300+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:01:30.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.714 seconds
[2025-09-20T21:02:01.077+0000] {processor.py:186} INFO - Started process (PID=1011) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:02:01.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:02:01.082+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:02:01.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:02:01.733+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:02:01.809+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:02:01.835+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:02:01.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:02:01.855+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:02:01.855+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:02:01.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.821 seconds
[2025-09-20T21:02:32.307+0000] {processor.py:186} INFO - Started process (PID=1040) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:02:32.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:02:32.311+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:02:32.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:02:32.902+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:02:32.970+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:02:33.005+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:02:33.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:02:33.020+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:02:33.020+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:02:33.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.745 seconds
[2025-09-20T21:03:03.764+0000] {processor.py:186} INFO - Started process (PID=1045) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:03:03.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:03:03.768+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:03:03.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:03:04.461+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:03:04.516+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:03:04.544+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:03:04.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:03:04.562+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:03:04.562+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:03:04.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.829 seconds
[2025-09-20T21:03:40.676+0000] {processor.py:186} INFO - Started process (PID=25) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:03:40.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:03:40.681+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:03:40.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:03:41.347+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:03:41.402+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:03:41.430+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:03:41.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:03:41.447+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:03:41.446+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:03:41.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.803 seconds
[2025-09-20T21:04:11.834+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:04:11.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:04:11.838+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:04:11.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:04:12.544+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:04:12.583+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:04:12.608+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:04:12.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:04:12.619+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:04:12.619+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:04:12.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.814 seconds
[2025-09-20T21:04:43.012+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:04:43.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:04:43.016+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:04:43.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:04:43.664+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:04:43.701+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:04:43.730+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:04:43.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:04:43.742+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:04:43.742+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:04:43.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.765 seconds
[2025-09-20T21:05:14.161+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:05:14.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:05:14.167+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:05:14.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:05:14.787+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:05:14.832+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:05:14.862+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:05:14.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:05:14.878+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:05:14.878+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:05:14.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.754 seconds
[2025-09-20T21:05:45.274+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:05:45.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:05:45.279+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:05:45.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:05:45.932+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:05:45.991+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:05:46.024+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:05:46.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:05:46.040+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:05:46.039+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:05:46.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.792 seconds
[2025-09-20T21:06:16.434+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:06:16.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:06:16.438+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:06:16.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:06:17.013+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:06:17.054+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:06:17.080+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:06:17.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:06:17.092+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:06:17.092+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:06:17.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.693 seconds
[2025-09-20T21:06:47.493+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:06:47.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:06:47.499+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:06:47.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:06:48.093+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:06:48.133+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:06:48.160+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:06:48.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:06:48.172+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:06:48.171+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:06:48.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.704 seconds
[2025-09-20T21:07:18.555+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:07:18.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:07:18.559+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:07:18.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:07:19.238+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:07:19.282+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:07:19.309+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:07:19.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:07:19.322+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:07:19.322+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:07:19.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.794 seconds
[2025-09-20T21:07:49.711+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:07:49.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:07:49.715+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:07:49.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:07:50.368+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:07:50.424+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:07:50.449+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:07:50.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:07:50.463+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:07:50.463+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:07:50.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.786 seconds
[2025-09-20T21:08:20.864+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:08:20.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:08:20.869+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:08:20.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:08:21.493+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:08:21.543+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:08:21.570+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:08:21.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:08:21.582+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:08:21.582+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:08:21.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.743 seconds
[2025-09-20T21:08:52.024+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:08:52.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:08:52.028+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:08:52.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:08:52.694+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:08:52.740+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:08:52.767+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:08:52.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:08:52.782+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:08:52.782+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:08:52.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.790 seconds
[2025-09-20T21:09:23.202+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:09:23.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:09:23.205+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:09:23.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:09:23.811+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:09:23.850+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:09:23.877+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:09:23.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:09:23.889+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:09:23.889+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:09:23.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.724 seconds
[2025-09-20T21:10:12.025+0000] {processor.py:186} INFO - Started process (PID=25) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:10:12.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:10:12.032+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:10:12.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:10:12.903+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:10:12.964+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:10:12.989+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:10:12.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:10:13.000+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:10:13.000+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:10:13.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.004 seconds
[2025-09-20T21:10:43.389+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:10:43.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:10:43.399+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:10:43.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:10:44.058+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:10:44.118+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:10:44.144+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:10:44.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:10:44.156+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:10:44.156+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:10:44.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.798 seconds
[2025-09-20T21:11:14.544+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:11:14.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:11:14.548+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:11:14.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:11:15.163+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:11:15.227+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:11:15.253+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:11:15.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:11:15.264+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:11:15.264+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:11:15.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.746 seconds
[2025-09-20T21:11:45.640+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:11:45.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:11:45.645+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:11:45.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:11:46.351+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:11:46.408+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:11:46.436+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:11:46.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:11:46.450+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:11:46.450+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:11:46.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.837 seconds
[2025-09-20T21:12:16.834+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:12:16.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:12:16.838+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:12:16.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:12:17.507+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:12:17.544+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:12:17.569+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:12:17.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:12:17.582+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:12:17.582+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:12:17.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.774 seconds
[2025-09-20T21:12:47.959+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:12:47.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:12:47.963+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:12:47.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:12:48.653+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:12:48.702+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:12:48.728+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:12:48.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:12:48.740+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:12:48.740+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:12:48.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.808 seconds
[2025-09-20T21:13:19.103+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:13:19.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:13:19.107+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:13:19.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:13:19.772+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:13:19.813+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:13:19.838+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:13:19.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:13:19.850+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:13:19.850+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:13:19.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.778 seconds
[2025-09-20T21:14:10.206+0000] {processor.py:186} INFO - Started process (PID=25) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:14:10.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:14:10.211+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:14:10.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:14:10.855+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:14:10.898+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:14:10.926+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:14:10.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:14:10.939+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:14:10.938+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:14:10.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.766 seconds
[2025-09-20T21:14:41.317+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:14:41.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:14:41.322+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:14:41.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:14:42.014+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:14:42.079+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:14:42.107+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:14:42.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:14:42.119+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:14:42.119+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:14:42.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.835 seconds
[2025-09-20T21:15:12.496+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:15:12.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:15:12.499+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:15:12.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:15:13.174+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:15:13.229+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:15:13.257+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:15:13.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:15:13.274+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:15:13.274+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:15:13.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.805 seconds
[2025-09-20T21:15:43.643+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:15:43.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:15:43.646+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:15:43.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:15:44.252+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:15:44.297+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:15:44.324+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:15:44.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:15:44.336+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:15:44.336+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:15:44.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.721 seconds
[2025-09-20T21:16:14.740+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:16:14.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:16:14.746+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:16:14.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:16:15.612+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:16:15.667+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:16:15.695+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:16:15.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:16:15.709+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:16:15.708+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:16:15.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.999 seconds
[2025-09-20T21:16:46.063+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:16:46.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:16:46.068+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:16:46.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:16:46.682+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:16:46.745+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:16:46.773+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:16:46.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:16:46.788+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:16:46.788+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:16:46.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T21:17:17.205+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:17:17.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:17:17.209+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:17:17.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:17:17.795+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:17:17.850+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:17:17.877+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:17:17.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:17:17.888+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:17:17.888+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:17:17.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.713 seconds
[2025-09-20T21:17:48.257+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:17:48.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:17:48.261+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:17:48.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:17:49.014+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:17:49.066+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:17:49.092+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:17:49.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:17:49.106+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:17:49.106+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:17:49.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.876 seconds
[2025-09-20T21:18:19.480+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:18:19.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:18:19.484+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:18:19.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:18:20.088+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:18:20.139+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:18:20.165+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:18:20.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:18:20.177+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:18:20.177+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:18:20.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.724 seconds
[2025-09-20T21:18:50.564+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:18:50.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:18:50.570+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:18:50.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:18:51.549+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:18:51.604+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:18:51.641+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:18:51.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:18:51.661+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:18:51.660+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:18:51.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.129 seconds
[2025-09-20T21:19:22.112+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:19:22.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:19:22.116+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:19:22.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:19:22.759+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:19:22.804+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:19:22.832+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:19:22.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:19:22.845+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:19:22.845+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:19:22.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.768 seconds
[2025-09-20T21:19:53.232+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:19:53.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:19:53.236+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:19:53.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:19:53.873+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:19:53.929+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:19:53.956+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:19:53.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:19:53.967+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:19:53.967+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:19:53.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.760 seconds
[2025-09-20T21:20:24.336+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:20:24.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:20:24.341+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:20:24.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:20:24.957+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:20:24.997+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:20:25.023+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:20:25.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:20:25.041+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:20:25.040+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:20:25.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.739 seconds
[2025-09-20T21:20:55.427+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:20:55.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:20:55.431+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:20:55.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:20:56.072+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:20:56.110+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:20:56.137+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:20:56.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:20:56.150+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:20:56.150+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:20:56.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.749 seconds
[2025-09-20T21:21:26.520+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:21:26.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:21:26.524+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:21:26.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:21:27.118+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:21:27.158+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:21:27.185+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:21:27.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:21:27.196+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:21:27.196+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:21:27.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.702 seconds
[2025-09-20T21:21:57.609+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:21:57.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:21:57.613+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:21:57.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:21:58.288+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:21:58.352+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:21:58.379+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:21:58.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:21:58.392+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:21:58.391+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:21:58.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.809 seconds
[2025-09-20T21:22:28.815+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:22:28.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:22:28.820+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:22:28.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:22:29.418+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:22:29.540+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:22:29.567+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:22:29.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:22:29.578+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:22:29.578+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:22:29.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.788 seconds
[2025-09-20T21:22:59.948+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:22:59.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:22:59.952+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:22:59.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:23:00.562+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:23:00.611+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:23:00.637+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:23:00.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:23:00.648+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:23:00.648+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:23:00.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.726 seconds
[2025-09-20T21:23:31.029+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:23:31.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:23:31.033+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:23:31.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:23:31.727+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:23:31.794+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:23:31.825+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:23:31.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:23:31.844+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:23:31.844+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:23:31.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.844 seconds
[2025-09-20T21:24:02.251+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:24:02.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:24:02.255+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:24:02.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:24:02.859+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:24:02.894+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:24:02.920+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:24:02.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:24:02.932+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:24:02.932+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:24:02.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.708 seconds
[2025-09-20T21:24:33.359+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:24:33.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:24:33.363+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:24:33.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:24:33.969+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:24:34.031+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:24:34.059+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:24:34.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:24:34.070+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:24:34.070+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:24:34.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.736 seconds
[2025-09-20T21:25:04.442+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:25:04.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:25:04.446+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:25:04.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:25:05.052+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:25:05.112+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:25:05.138+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:25:05.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:25:05.149+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:25:05.149+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:25:05.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.733 seconds
[2025-09-20T21:25:35.554+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:25:35.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:25:35.560+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:25:35.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:25:36.234+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:25:36.282+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:25:36.309+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:25:36.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:25:36.321+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:25:36.320+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:25:36.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.794 seconds
[2025-09-20T21:26:06.704+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:26:06.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:26:06.708+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:26:06.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:26:07.344+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:26:07.390+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:26:07.417+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:26:07.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:26:07.429+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:26:07.429+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:26:07.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.759 seconds
[2025-09-20T21:26:37.820+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:26:37.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:26:37.824+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:26:37.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:26:38.435+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:26:38.487+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:26:38.513+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:26:38.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:26:38.526+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:26:38.526+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:26:38.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.732 seconds
[2025-09-20T21:27:08.902+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:27:08.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:27:08.906+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:27:08.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:27:09.505+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:27:09.543+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:27:09.569+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:27:09.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:27:09.581+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:27:09.581+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:27:09.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.707 seconds
[2025-09-20T21:27:39.968+0000] {processor.py:186} INFO - Started process (PID=221) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:27:39.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:27:39.972+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:27:39.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:27:40.622+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:27:40.665+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:27:40.691+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:27:40.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:27:40.703+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:27:40.703+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:27:40.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.761 seconds
[2025-09-20T21:28:11.077+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:28:11.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:28:11.081+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:28:11.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:28:11.697+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:28:11.736+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:28:11.761+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:28:11.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:28:11.773+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:28:11.773+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:28:11.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.722 seconds
[2025-09-20T21:28:42.158+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:28:42.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:28:42.162+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:28:42.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:28:42.767+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:28:42.810+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:28:42.834+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:28:42.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:28:42.846+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:28:42.845+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:28:42.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.722 seconds
[2025-09-20T21:29:13.390+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:29:13.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:29:13.397+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:29:13.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:29:14.088+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:29:14.128+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:29:14.153+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:29:14.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:29:14.165+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:29:14.165+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:29:14.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.815 seconds
[2025-09-20T21:29:44.571+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:29:44.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:29:44.576+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:29:44.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:29:45.286+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:29:45.324+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:29:45.348+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:29:45.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:29:45.360+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:29:45.360+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:29:45.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.818 seconds
[2025-09-20T21:30:15.739+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:30:15.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:30:15.743+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:30:15.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:30:16.363+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:30:16.404+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:30:16.430+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:30:16.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:30:16.441+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:30:16.441+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:30:16.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.730 seconds
[2025-09-20T21:30:46.825+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:30:46.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:30:46.829+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:30:46.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:30:47.496+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:30:47.576+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:30:47.605+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:30:47.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:30:47.616+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:30:47.616+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:30:47.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.818 seconds
[2025-09-20T21:31:18.002+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:31:18.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:31:18.006+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:31:18.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:31:18.608+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:31:18.675+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:31:18.701+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:31:18.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:31:18.713+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:31:18.713+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:31:18.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.738 seconds
[2025-09-20T21:31:49.095+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:31:49.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:31:49.100+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:31:49.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:31:49.708+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:31:49.768+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:31:49.794+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:31:49.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:31:49.805+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:31:49.805+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:31:49.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.736 seconds
[2025-09-20T21:32:20.190+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:32:20.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:32:20.194+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:32:20.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:32:20.816+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:32:20.866+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:32:20.895+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:32:20.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:32:20.909+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:32:20.909+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:32:20.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.747 seconds
[2025-09-20T21:32:51.295+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:32:51.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:32:51.299+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:32:51.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:32:51.924+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:32:51.960+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:32:51.987+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:32:51.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:32:51.999+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:32:51.999+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:32:52.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.742 seconds
[2025-09-20T21:33:22.384+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:33:22.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:33:22.388+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:33:22.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:33:22.995+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:33:23.048+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:33:23.075+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:33:23.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:33:23.087+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:33:23.087+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:33:23.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.733 seconds
[2025-09-20T21:33:53.572+0000] {processor.py:186} INFO - Started process (PID=281) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:33:53.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:33:53.581+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:33:53.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:33:54.242+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:33:54.283+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:33:54.310+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:33:54.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:33:54.323+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:33:54.322+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:33:54.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.782 seconds
[2025-09-20T21:34:24.757+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:34:24.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:34:24.761+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:34:24.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:34:25.489+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:34:25.534+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:34:25.560+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:34:25.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:34:25.572+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:34:25.572+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:34:25.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.841 seconds
[2025-09-20T21:34:55.960+0000] {processor.py:186} INFO - Started process (PID=291) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:34:55.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:34:55.964+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:34:55.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:34:56.568+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:34:56.608+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:34:56.635+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:34:56.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:34:56.646+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:34:56.646+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:34:56.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.721 seconds
[2025-09-20T21:35:27.036+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:35:27.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:35:27.042+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:35:27.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:35:27.688+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:35:27.731+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:35:27.757+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:35:27.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:35:27.769+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:35:27.768+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:35:27.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.760 seconds
[2025-09-20T21:35:58.155+0000] {processor.py:186} INFO - Started process (PID=301) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:35:58.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:35:58.160+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:35:58.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:35:58.786+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:35:58.824+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:35:58.850+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:35:58.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:35:58.861+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:35:58.861+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:35:58.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.735 seconds
[2025-09-20T21:36:29.235+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:36:29.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:36:29.239+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:36:29.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:36:29.817+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:36:29.875+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:36:29.901+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:36:29.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:36:29.913+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:36:29.913+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:36:29.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.714 seconds
[2025-09-20T21:37:00.338+0000] {processor.py:186} INFO - Started process (PID=311) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:37:00.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:37:00.343+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:37:00.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:37:00.923+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:37:00.961+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:37:00.987+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:37:00.987+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:37:00.998+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:37:00.998+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:37:01.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.695 seconds
[2025-09-20T21:37:31.385+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:37:31.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:37:31.391+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:37:31.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:37:31.949+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:37:31.990+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:37:32.016+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:37:32.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:37:32.027+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:37:32.027+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:37:32.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.677 seconds
[2025-09-20T21:38:02.415+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:38:02.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:38:02.419+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:38:02.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:38:03.001+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:38:03.042+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:38:03.080+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:38:03.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:38:03.093+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:38:03.093+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:38:03.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.703 seconds
[2025-09-20T21:38:33.490+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:38:33.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:38:33.495+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:38:33.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:38:34.132+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:38:34.172+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:38:34.198+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:38:34.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:38:34.213+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:38:34.212+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:38:34.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.759 seconds
[2025-09-20T21:39:04.643+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:39:04.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:39:04.647+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:39:04.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:39:05.341+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:39:05.379+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:39:05.407+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:39:05.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:39:05.420+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:39:05.420+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:39:05.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.855 seconds
[2025-09-20T21:39:35.953+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:39:35.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:39:35.956+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:39:35.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:39:36.594+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:39:36.632+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:39:36.658+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:39:36.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:39:36.670+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:39:36.670+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:39:36.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.751 seconds
[2025-09-20T21:40:07.051+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:40:07.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:40:07.056+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:40:07.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:40:07.661+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:40:07.699+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:40:07.726+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:40:07.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:40:07.746+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:40:07.745+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:40:07.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.720 seconds
[2025-09-20T21:40:38.130+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:40:38.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:40:38.134+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:40:38.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:40:38.735+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:40:38.788+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:40:38.816+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:40:38.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:40:38.827+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:40:38.827+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:40:38.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.723 seconds
[2025-09-20T21:41:09.210+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:41:09.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:41:09.214+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:41:09.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:41:09.813+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:41:09.848+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:41:09.875+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:41:09.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:41:09.892+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:41:09.892+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:41:09.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.705 seconds
[2025-09-20T21:41:40.307+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:41:40.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:41:40.311+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:41:40.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:41:40.981+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:41:41.027+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:41:41.055+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:41:41.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:41:41.067+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:41:41.066+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:41:41.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.787 seconds
[2025-09-20T21:42:11.465+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:42:11.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:42:11.469+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:42:11.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:42:12.099+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:42:12.163+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:42:12.191+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:42:12.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:42:12.203+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:42:12.203+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:42:12.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.766 seconds
[2025-09-20T21:42:42.627+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:42:42.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:42:42.630+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:42:42.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:42:43.229+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:42:43.281+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:42:43.308+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:42:43.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:42:43.320+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:42:43.319+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:42:43.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.718 seconds
[2025-09-20T21:43:13.705+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:43:13.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:43:13.708+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:43:13.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:43:14.343+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:43:14.383+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:43:14.409+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:43:14.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:43:14.420+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:43:14.420+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:43:14.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.756 seconds
[2025-09-20T21:43:44.819+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:43:44.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:43:44.824+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:43:44.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:43:45.546+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:43:45.597+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:43:45.624+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:43:45.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:43:45.638+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:43:45.637+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:43:45.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.853 seconds
[2025-09-20T21:44:16.110+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:44:16.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:44:16.115+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:44:16.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:44:16.765+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:44:16.821+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:44:16.848+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:44:16.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:44:16.861+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:44:16.860+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:44:16.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.777 seconds
[2025-09-20T21:44:47.306+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:44:47.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:44:47.310+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:44:47.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:44:47.912+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:44:47.955+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:44:47.982+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:44:47.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:44:47.993+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:44:47.993+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:44:48.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.716 seconds
[2025-09-20T21:45:18.379+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:45:18.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:45:18.383+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:45:18.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:45:18.995+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:45:19.054+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:45:19.079+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:45:19.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:45:19.091+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:45:19.091+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:45:19.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.739 seconds
[2025-09-20T21:45:49.472+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:45:49.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:45:49.475+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:45:49.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:45:50.088+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:45:50.129+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:45:50.155+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:45:50.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:45:50.166+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:45:50.166+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:45:50.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.724 seconds
[2025-09-20T21:46:20.553+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:46:20.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:46:20.558+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:46:20.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:46:21.230+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:46:21.271+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:46:21.305+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:46:21.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:46:21.318+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:46:21.317+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:46:21.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.806 seconds
[2025-09-20T21:46:51.721+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:46:51.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:46:51.725+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:46:51.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:46:52.368+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:46:52.405+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:46:52.430+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:46:52.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:46:52.443+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:46:52.442+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:46:52.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T21:47:22.843+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:47:22.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:47:22.847+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:47:22.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:47:23.471+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:47:23.527+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:47:23.553+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:47:23.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:47:23.564+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:47:23.564+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:47:23.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.748 seconds
[2025-09-20T21:47:53.955+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:47:53.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:47:53.962+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:47:53.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:47:54.630+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:47:54.671+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:47:54.696+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:47:54.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:47:54.708+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:47:54.708+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:47:54.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.785 seconds
[2025-09-20T21:48:25.577+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:48:25.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:48:25.581+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:48:25.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:48:26.274+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:48:26.334+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:48:26.361+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:48:26.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:48:26.375+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:48:26.375+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:48:26.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 1.338 seconds
[2025-09-20T21:48:56.730+0000] {processor.py:186} INFO - Started process (PID=426) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:48:56.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:48:56.735+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:48:56.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:48:57.533+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:48:57.578+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:48:57.609+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:48:57.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:48:57.626+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:48:57.625+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:48:57.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.927 seconds
[2025-09-20T21:49:28.171+0000] {processor.py:186} INFO - Started process (PID=431) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:49:28.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:49:28.176+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:49:28.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:49:28.799+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:49:28.840+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:49:28.865+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:49:28.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:49:28.877+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:49:28.877+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:49:28.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.734 seconds
[2025-09-20T21:49:59.263+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:49:59.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:49:59.269+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:49:59.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:49:59.916+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:49:59.982+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:50:00.013+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:50:00.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:50:00.024+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:50:00.024+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:50:00.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.793 seconds
[2025-09-20T21:50:30.419+0000] {processor.py:186} INFO - Started process (PID=441) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:50:30.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:50:30.423+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:50:30.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:50:31.025+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:50:31.060+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:50:31.085+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:50:31.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:50:31.097+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:50:31.096+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:50:31.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.713 seconds
[2025-09-20T21:51:01.484+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:51:01.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:51:01.488+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:51:01.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:51:02.139+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:51:02.175+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:51:02.201+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:51:02.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:51:02.213+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:51:02.213+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:51:02.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.761 seconds
[2025-09-20T21:51:32.615+0000] {processor.py:186} INFO - Started process (PID=451) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:51:32.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:51:32.619+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:51:32.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:51:33.214+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:51:33.253+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:51:33.279+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:51:33.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:51:33.291+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:51:33.290+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:51:33.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.713 seconds
[2025-09-20T21:52:03.677+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:52:03.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:52:03.681+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:52:03.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:52:04.300+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:52:04.348+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:52:04.390+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:52:04.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:52:04.412+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:52:04.412+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:52:04.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.771 seconds
[2025-09-20T21:52:34.816+0000] {processor.py:186} INFO - Started process (PID=461) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:52:34.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:52:34.820+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:52:34.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:52:35.408+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:52:35.447+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:52:35.475+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:52:35.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:52:35.487+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:52:35.487+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:52:35.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.709 seconds
[2025-09-20T21:53:05.886+0000] {processor.py:186} INFO - Started process (PID=466) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:53:05.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:53:05.890+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:53:05.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:53:06.603+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:53:06.656+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:53:06.684+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:53:06.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:53:06.698+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:53:06.698+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:53:06.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.841 seconds
[2025-09-20T21:53:37.066+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:53:37.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:53:37.071+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:53:37.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:53:37.739+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:53:37.791+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:53:37.821+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:53:37.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:53:37.836+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:53:37.836+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:53:37.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.800 seconds
[2025-09-20T21:54:08.169+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:54:08.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:54:08.173+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:54:08.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:54:08.831+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:54:08.892+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:54:08.922+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:54:08.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:54:08.936+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:54:08.936+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:54:08.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.795 seconds
[2025-09-20T21:54:39.337+0000] {processor.py:186} INFO - Started process (PID=481) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:54:39.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:54:39.340+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:54:39.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:54:39.981+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:54:40.041+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:54:40.083+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:54:40.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:54:40.100+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:54:40.100+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:54:40.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.796 seconds
[2025-09-20T21:55:10.478+0000] {processor.py:186} INFO - Started process (PID=486) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:55:10.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:55:10.482+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:55:10.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:55:11.111+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:55:11.155+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:55:11.180+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:55:11.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:55:11.193+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:55:11.192+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:55:11.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.742 seconds
[2025-09-20T21:55:41.583+0000] {processor.py:186} INFO - Started process (PID=491) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:55:41.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:55:41.588+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:55:41.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:55:42.207+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:55:42.272+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:55:42.299+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:55:42.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:55:42.311+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:55:42.311+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:55:42.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.756 seconds
[2025-09-20T21:56:12.691+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:56:12.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:56:12.695+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:56:12.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:56:13.326+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:56:13.384+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:56:13.409+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:56:13.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:56:13.420+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:56:13.419+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:56:13.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.757 seconds
[2025-09-20T21:56:43.804+0000] {processor.py:186} INFO - Started process (PID=501) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:56:43.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:56:43.808+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:56:43.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:56:44.388+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:56:44.426+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:56:44.452+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:56:44.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:56:44.464+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:56:44.464+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:56:44.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.688 seconds
[2025-09-20T21:57:14.857+0000] {processor.py:186} INFO - Started process (PID=506) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:57:14.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:57:14.863+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:57:14.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:57:15.505+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:57:15.556+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:57:15.583+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:57:15.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:57:15.594+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:57:15.594+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:57:15.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.765 seconds
[2025-09-20T21:57:45.982+0000] {processor.py:186} INFO - Started process (PID=511) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:57:45.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:57:45.986+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:57:45.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:57:46.637+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:57:46.709+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:57:46.735+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:57:46.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:57:46.748+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:57:46.748+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:57:46.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.795 seconds
[2025-09-20T21:58:17.135+0000] {processor.py:186} INFO - Started process (PID=516) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:58:17.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:58:17.140+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:58:17.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:58:17.823+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:58:17.888+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:58:17.916+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:58:17.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:58:17.927+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:58:17.927+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:58:17.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.819 seconds
[2025-09-20T21:58:48.348+0000] {processor.py:186} INFO - Started process (PID=521) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:58:48.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:58:48.352+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:58:48.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:58:48.948+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:58:48.989+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:58:49.015+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:58:49.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:58:49.026+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:58:49.026+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:58:49.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.705 seconds
[2025-09-20T21:59:19.464+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:59:19.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:59:19.467+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:59:19.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:59:20.109+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:59:20.156+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:59:20.182+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:59:20.182+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:59:20.194+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:59:20.194+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:59:20.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.765 seconds
[2025-09-20T21:59:50.586+0000] {processor.py:186} INFO - Started process (PID=531) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:59:50.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T21:59:50.590+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:59:50.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:59:51.222+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T21:59:51.282+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T21:59:51.308+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:59:51.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T21:59:51.319+0000] {logging_mixin.py:190} INFO - [2025-09-20T21:59:51.319+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T21:59:51.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.765 seconds
[2025-09-20T22:00:21.841+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:00:21.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:00:21.845+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:00:21.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:00:22.538+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:00:22.590+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:00:22.617+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:00:22.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:00:22.631+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:00:22.631+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:00:22.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.816 seconds
[2025-09-20T22:00:53.055+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:00:53.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:00:53.059+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:00:53.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:00:53.688+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:00:53.727+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:00:53.753+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:00:53.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:00:53.767+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:00:53.767+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:00:53.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.743 seconds
[2025-09-20T22:01:24.535+0000] {processor.py:186} INFO - Started process (PID=547) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:01:24.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:01:24.539+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:01:24.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:01:25.218+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:01:25.252+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:01:25.278+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:01:25.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:01:25.290+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:01:25.289+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:01:25.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.789 seconds
[2025-09-20T22:01:56.023+0000] {processor.py:186} INFO - Started process (PID=552) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:01:56.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:01:56.027+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:01:56.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:01:56.668+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:01:56.713+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:01:56.741+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:01:56.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:01:56.755+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:01:56.755+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:01:56.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.762 seconds
[2025-09-20T22:02:27.028+0000] {processor.py:186} INFO - Started process (PID=557) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:02:27.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:02:27.033+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:02:27.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:02:27.758+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:02:27.805+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:02:27.831+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:02:27.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:02:27.844+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:02:27.844+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:02:27.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.858 seconds
[2025-09-20T22:02:58.229+0000] {processor.py:186} INFO - Started process (PID=562) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:02:58.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:02:58.233+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:02:58.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:02:58.863+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:02:58.922+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:02:58.949+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:02:58.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:02:58.961+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:02:58.960+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:02:58.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.761 seconds
[2025-09-20T22:03:29.367+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:03:29.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:03:29.372+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:03:29.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:03:30.059+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:03:30.106+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:03:30.134+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:03:30.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:03:30.148+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:03:30.148+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:03:30.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.811 seconds
[2025-09-20T22:04:00.822+0000] {processor.py:186} INFO - Started process (PID=572) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:04:00.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:04:00.827+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:04:00.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:04:01.506+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:04:01.565+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:04:01.594+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:04:01.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:04:01.608+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:04:01.608+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:04:01.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.818 seconds
[2025-09-20T22:04:32.083+0000] {processor.py:186} INFO - Started process (PID=577) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:04:32.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:04:32.087+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:04:32.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:04:32.753+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:04:32.812+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:04:32.838+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:04:32.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:04:32.850+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:04:32.850+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:04:32.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.795 seconds
[2025-09-20T22:05:03.245+0000] {processor.py:186} INFO - Started process (PID=582) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:05:03.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:05:03.249+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:05:03.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:05:03.877+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:05:03.923+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:05:03.950+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:05:03.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:05:03.963+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:05:03.963+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:05:03.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.747 seconds
[2025-09-20T22:05:34.738+0000] {processor.py:186} INFO - Started process (PID=587) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:05:34.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:05:34.742+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:05:34.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:05:35.468+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:05:35.521+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:05:35.547+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:05:35.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:05:35.559+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:05:35.559+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:05:35.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.848 seconds
[2025-09-20T22:06:05.944+0000] {processor.py:186} INFO - Started process (PID=592) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:06:05.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:06:05.951+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:06:05.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:06:06.625+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:06:06.675+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:06:06.703+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:06:06.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:06:06.717+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:06:06.717+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:06:06.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.811 seconds
[2025-09-20T22:06:37.405+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:06:37.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:06:37.409+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:06:37.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:06:38.102+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:06:38.139+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:06:38.165+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:06:38.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:06:38.177+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:06:38.177+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:06:38.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.807 seconds
[2025-09-20T22:07:08.869+0000] {processor.py:186} INFO - Started process (PID=602) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:07:08.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:07:08.873+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:07:08.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:07:09.526+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:07:09.571+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:07:09.599+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:07:09.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:07:09.614+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:07:09.614+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:07:09.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.780 seconds
[2025-09-20T22:07:40.354+0000] {processor.py:186} INFO - Started process (PID=607) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:07:40.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:07:40.359+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:07:40.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:07:41.100+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:07:41.144+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:07:41.173+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:07:41.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:07:41.189+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:07:41.188+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:07:41.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.866 seconds
[2025-09-20T22:08:11.767+0000] {processor.py:186} INFO - Started process (PID=614) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:08:11.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:08:11.774+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:08:11.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:08:12.419+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:08:12.478+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:08:12.503+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:08:12.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:08:12.513+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:08:12.513+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:08:12.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.777 seconds
[2025-09-20T22:08:42.896+0000] {processor.py:186} INFO - Started process (PID=618) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:08:42.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:08:42.902+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:08:42.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:08:43.681+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:08:43.715+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:08:43.742+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:08:43.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:08:43.756+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:08:43.755+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:08:43.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.891 seconds
[2025-09-20T22:09:14.275+0000] {processor.py:186} INFO - Started process (PID=623) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:09:14.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:09:14.279+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:09:14.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:09:14.986+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:09:15.029+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:09:15.060+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:09:15.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:09:15.076+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:09:15.076+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:09:15.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.833 seconds
[2025-09-20T22:09:45.594+0000] {processor.py:186} INFO - Started process (PID=628) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:09:45.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:09:45.599+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:09:45.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:09:46.269+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:09:46.322+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:09:46.352+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:09:46.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:09:46.366+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:09:46.366+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:09:46.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.802 seconds
[2025-09-20T22:10:16.732+0000] {processor.py:186} INFO - Started process (PID=633) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:10:16.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:10:16.737+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:10:16.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:10:17.379+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:10:17.420+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:10:17.449+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:10:17.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:10:17.463+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:10:17.463+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:10:17.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.757 seconds
[2025-09-20T22:10:48.158+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:10:48.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:10:48.164+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:10:48.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:10:50.425+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:10:50.503+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:10:50.584+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:10:50.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:10:50.623+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:10:50.623+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:10:50.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 2.535 seconds
[2025-09-20T22:11:21.053+0000] {processor.py:186} INFO - Started process (PID=643) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:11:21.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:11:21.057+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:11:21.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:11:21.757+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:11:21.791+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:11:21.817+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:11:21.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:11:21.828+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:11:21.828+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:11:21.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.807 seconds
[2025-09-20T22:11:52.340+0000] {processor.py:186} INFO - Started process (PID=648) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:11:52.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:11:52.346+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:11:52.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:11:53.067+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:11:53.113+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:11:53.139+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:11:53.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:11:53.152+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:11:53.152+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:11:53.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.842 seconds
[2025-09-20T22:12:23.562+0000] {processor.py:186} INFO - Started process (PID=653) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:12:23.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:12:23.566+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:12:23.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:12:24.229+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:12:24.269+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:12:24.296+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:12:24.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:12:24.308+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:12:24.308+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:12:24.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.778 seconds
[2025-09-20T22:12:55.014+0000] {processor.py:186} INFO - Started process (PID=658) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:12:55.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:12:55.018+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:12:55.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:12:55.704+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:12:55.759+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:12:55.785+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:12:55.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:12:55.800+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:12:55.799+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:12:55.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.814 seconds
[2025-09-20T22:13:26.276+0000] {processor.py:186} INFO - Started process (PID=663) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:13:26.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:13:26.280+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:13:26.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:13:26.989+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:13:27.033+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:13:27.059+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:13:27.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:13:27.071+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:13:27.070+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:13:27.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.829 seconds
[2025-09-20T22:13:57.462+0000] {processor.py:186} INFO - Started process (PID=668) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:13:57.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:13:57.466+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:13:57.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:13:58.248+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:13:58.301+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:13:58.329+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:13:58.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:13:58.342+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:13:58.341+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:13:58.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.921 seconds
[2025-09-20T22:14:28.952+0000] {processor.py:186} INFO - Started process (PID=673) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:14:28.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:14:28.956+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:14:28.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:14:29.684+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:14:29.722+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:14:29.750+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:14:29.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:14:29.765+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:14:29.765+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:14:29.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.848 seconds
[2025-09-20T22:15:00.299+0000] {processor.py:186} INFO - Started process (PID=678) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:15:00.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:15:00.304+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:15:00.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:15:01.063+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:15:01.118+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:15:01.146+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:15:01.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:15:01.159+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:15:01.158+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:15:01.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.888 seconds
[2025-09-20T22:15:31.566+0000] {processor.py:186} INFO - Started process (PID=683) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:15:31.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:15:31.571+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:15:31.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:15:32.216+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:15:32.256+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:15:32.282+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:15:32.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:15:32.294+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:15:32.293+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:15:32.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.766 seconds
[2025-09-20T22:16:03.098+0000] {processor.py:186} INFO - Started process (PID=690) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:16:03.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:16:03.102+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:16:03.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:16:03.791+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:16:03.843+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:16:03.868+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:16:03.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:16:03.879+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:16:03.879+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:16:03.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.808 seconds
[2025-09-20T22:16:34.274+0000] {processor.py:186} INFO - Started process (PID=694) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:16:34.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:16:34.278+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:16:34.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:16:34.889+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:16:34.931+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:16:34.959+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:16:34.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:16:34.970+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:16:34.970+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:16:34.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.724 seconds
[2025-09-20T22:17:05.327+0000] {processor.py:186} INFO - Started process (PID=698) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:17:05.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:17:05.330+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:17:05.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:17:05.995+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:17:06.034+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:17:06.061+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:17:06.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:17:06.077+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:17:06.077+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:17:06.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.782 seconds
[2025-09-20T22:17:36.407+0000] {processor.py:186} INFO - Started process (PID=702) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:17:36.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:17:36.410+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:17:36.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:17:37.067+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:17:37.121+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:17:37.149+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:17:37.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:17:37.161+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:17:37.160+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:17:37.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.783 seconds
[2025-09-20T22:18:07.477+0000] {processor.py:186} INFO - Started process (PID=706) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:18:07.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:18:07.479+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:18:07.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:18:08.132+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:18:08.176+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:18:08.208+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:18:08.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:18:08.230+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:18:08.230+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:18:08.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.787 seconds
[2025-09-20T22:18:38.568+0000] {processor.py:186} INFO - Started process (PID=710) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:18:38.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:18:38.571+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:18:38.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:18:39.198+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:18:39.237+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:18:39.263+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:18:39.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:18:39.278+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:18:39.278+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:18:39.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.747 seconds
[2025-09-20T22:19:09.615+0000] {processor.py:186} INFO - Started process (PID=714) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:19:09.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:19:09.617+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:19:09.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:19:10.274+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:19:10.318+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:19:10.346+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:19:10.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:19:10.357+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:19:10.357+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:19:10.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.770 seconds
[2025-09-20T22:19:40.666+0000] {processor.py:186} INFO - Started process (PID=718) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:19:40.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:19:40.669+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:19:40.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:19:41.458+0000] {logging_mixin.py:190} INFO -     user_id  ... signup_date
0         1  ...  2024-10-27
1         2  ...  2024-04-17
2         3  ...  2024-01-26
3         4  ...  2024-10-18
4         5  ...  2024-02-28
..      ...  ...         ...
95       96  ...  2024-01-02
96       97  ...  2025-06-03
97       98  ...  2025-02-15
98       99  ...  2025-08-04
99      100  ...  2024-08-20

[100 rows x 4 columns]
[2025-09-20T22:19:41.514+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:19:41.541+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:19:41.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:19:41.554+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:19:41.554+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:19:41.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.914 seconds
[2025-09-20T22:20:11.967+0000] {processor.py:186} INFO - Started process (PID=722) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:20:11.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:20:11.971+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:20:11.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:20:12.826+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:20:12.853+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:20:12.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:20:12.866+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:20:12.865+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:20:12.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.932 seconds
[2025-09-20T22:20:40.167+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:20:40.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:20:40.170+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:20:40.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:20:40.871+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:20:40.899+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:20:40.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:20:40.912+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:20:40.911+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:20:40.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.779 seconds
[2025-09-20T22:21:11.027+0000] {processor.py:186} INFO - Started process (PID=729) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:21:11.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:21:11.030+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:21:11.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:21:11.741+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:21:11.769+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:21:11.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:21:11.780+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:21:11.780+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:21:11.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.787 seconds
[2025-09-20T22:21:42.690+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:21:42.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:21:42.693+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:21:42.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:21:43.319+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:21:43.347+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:21:43.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:21:43.359+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:21:43.359+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:21:43.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.695 seconds
[2025-09-20T22:22:13.677+0000] {processor.py:186} INFO - Started process (PID=737) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:22:13.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:22:13.680+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:22:13.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:22:14.290+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:22:14.316+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:22:14.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:22:14.327+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:22:14.327+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:22:14.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.679 seconds
[2025-09-20T22:22:44.654+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:22:44.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:22:44.658+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:22:44.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:22:45.273+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:22:45.297+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:22:45.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:22:45.309+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:22:45.309+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:22:45.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.682 seconds
[2025-09-20T22:23:15.632+0000] {processor.py:186} INFO - Started process (PID=745) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:23:15.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:23:15.635+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:23:15.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:23:16.335+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:23:16.362+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:23:16.361+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:23:16.375+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:23:16.375+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:23:16.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.779 seconds
[2025-09-20T22:23:46.713+0000] {processor.py:186} INFO - Started process (PID=749) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:23:46.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:23:46.716+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:23:46.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:23:47.355+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:23:47.382+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:23:47.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:23:47.393+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:23:47.393+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:23:47.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.709 seconds
[2025-09-20T22:24:17.789+0000] {processor.py:186} INFO - Started process (PID=753) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:24:17.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:24:17.791+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:24:17.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:24:18.413+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:24:18.441+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:24:18.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:24:18.453+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:24:18.453+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:24:18.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.696 seconds
[2025-09-20T22:24:48.772+0000] {processor.py:186} INFO - Started process (PID=757) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:24:48.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:24:48.775+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:24:48.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:24:49.431+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:24:49.457+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:24:49.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:24:49.469+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:24:49.469+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:24:49.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.738 seconds
[2025-09-20T22:25:19.590+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:25:19.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:25:19.593+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:25:19.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:25:20.190+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:25:20.216+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:25:20.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:25:20.228+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:25:20.228+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:25:20.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.668 seconds
[2025-09-20T22:25:50.552+0000] {processor.py:186} INFO - Started process (PID=765) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:25:50.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:25:50.555+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:25:50.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:25:51.207+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:25:51.236+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:25:51.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:25:51.251+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:25:51.251+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:25:51.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.731 seconds
[2025-09-20T22:26:22.111+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:26:22.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:26:22.114+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:26:22.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:26:22.809+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:26:22.839+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:26:22.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:26:22.857+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:26:22.856+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:26:22.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.785 seconds
[2025-09-20T22:26:53.193+0000] {processor.py:186} INFO - Started process (PID=773) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:26:53.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:26:53.196+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:26:53.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:26:53.876+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:26:53.905+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:26:53.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:26:53.917+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:26:53.917+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:26:53.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.752 seconds
[2025-09-20T22:27:24.275+0000] {processor.py:186} INFO - Started process (PID=777) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:27:24.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:27:24.280+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:27:24.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:27:24.982+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:27:25.012+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:27:25.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:27:25.026+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:27:25.026+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:27:25.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.785 seconds
[2025-09-20T22:27:55.137+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:27:55.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:27:55.139+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:27:55.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:27:55.780+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:27:55.807+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:27:55.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:27:55.818+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:27:55.818+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:27:55.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.712 seconds
[2025-09-20T22:28:26.149+0000] {processor.py:186} INFO - Started process (PID=785) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:28:26.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:28:26.154+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:28:26.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:28:26.810+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:28:26.837+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:28:26.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:28:26.849+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:28:26.849+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:28:26.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.735 seconds
[2025-09-20T22:28:57.169+0000] {processor.py:186} INFO - Started process (PID=789) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:28:57.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:28:57.172+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:28:57.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:28:57.947+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:28:57.976+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:28:57.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:28:57.989+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:28:57.989+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:28:58.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.847 seconds
[2025-09-20T22:29:28.460+0000] {processor.py:186} INFO - Started process (PID=793) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:29:28.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:29:28.462+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:29:28.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:29:29.150+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:29:29.176+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:29:29.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:29:29.190+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:29:29.190+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:29:29.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.766 seconds
[2025-09-20T22:29:59.509+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:29:59.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:29:59.512+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:29:59.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:30:00.192+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:30:00.217+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:30:00.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:30:00.228+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:30:00.228+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:30:00.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.748 seconds
[2025-09-20T22:30:30.559+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:30:30.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:30:30.562+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:30:30.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:30:31.229+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:30:31.257+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:30:31.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:30:31.272+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:30:31.271+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:30:31.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.740 seconds
[2025-09-20T22:31:01.593+0000] {processor.py:186} INFO - Started process (PID=805) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:31:01.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:31:01.595+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:31:01.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:31:02.246+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:31:02.269+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:31:02.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:31:02.280+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:31:02.280+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:31:02.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.715 seconds
[2025-09-20T22:31:32.711+0000] {processor.py:186} INFO - Started process (PID=809) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:31:32.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:31:32.714+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:31:32.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:31:33.295+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:31:33.321+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:31:33.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:31:33.333+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:31:33.333+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:31:33.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.650 seconds
[2025-09-20T22:32:03.662+0000] {processor.py:186} INFO - Started process (PID=813) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:32:03.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:32:03.665+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:32:03.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:32:04.279+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:32:04.303+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:32:04.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:32:04.314+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:32:04.314+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:32:04.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.684 seconds
[2025-09-20T22:32:34.652+0000] {processor.py:186} INFO - Started process (PID=817) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:32:34.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:32:34.655+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:32:34.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:32:35.268+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:32:35.293+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:32:35.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:32:35.307+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:32:35.307+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:32:35.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.683 seconds
[2025-09-20T22:33:05.650+0000] {processor.py:186} INFO - Started process (PID=821) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:33:05.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:33:05.653+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:33:05.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:33:06.326+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:33:06.366+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:33:06.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:33:06.383+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:33:06.382+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:33:06.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.767 seconds
[2025-09-20T22:33:36.704+0000] {processor.py:186} INFO - Started process (PID=825) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:33:36.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:33:36.707+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:33:36.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:33:37.350+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:33:37.376+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:33:37.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:33:37.388+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:33:37.388+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:33:37.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.719 seconds
[2025-09-20T22:34:08.204+0000] {processor.py:186} INFO - Started process (PID=829) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:34:08.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:34:08.206+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:34:08.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:34:08.890+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:34:08.917+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:34:08.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:34:08.939+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:34:08.939+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:34:08.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.773 seconds
[2025-09-20T22:34:39.277+0000] {processor.py:186} INFO - Started process (PID=833) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:34:39.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:34:39.280+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:34:39.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:34:39.890+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:34:39.916+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:34:39.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:34:39.928+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:34:39.928+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:34:39.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.686 seconds
[2025-09-20T22:35:10.250+0000] {processor.py:186} INFO - Started process (PID=837) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:35:10.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:35:10.253+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:35:10.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:35:10.873+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:35:10.901+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:35:10.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:35:10.912+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:35:10.912+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:35:10.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.689 seconds
[2025-09-20T22:35:41.277+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:35:41.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:35:41.280+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:35:41.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:35:41.898+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:35:41.926+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:35:41.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:35:41.939+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:35:41.939+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:35:41.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.700 seconds
[2025-09-20T22:36:12.261+0000] {processor.py:186} INFO - Started process (PID=845) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:36:12.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:36:12.264+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:36:12.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:36:12.929+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:36:12.956+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:36:12.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:36:12.969+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:36:12.969+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:36:12.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.739 seconds
[2025-09-20T22:36:43.399+0000] {processor.py:186} INFO - Started process (PID=849) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:36:43.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:36:43.402+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:36:43.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:36:44.027+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:36:44.053+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:36:44.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:36:44.064+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:36:44.064+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:36:44.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.694 seconds
[2025-09-20T22:37:14.387+0000] {processor.py:186} INFO - Started process (PID=853) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:37:14.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:37:14.389+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:37:14.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:37:15.014+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:37:15.042+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:37:15.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:37:15.054+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:37:15.053+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:37:15.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.697 seconds
[2025-09-20T22:37:45.371+0000] {processor.py:186} INFO - Started process (PID=857) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:37:45.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:37:45.373+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:37:45.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:37:46.040+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:37:46.074+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:37:46.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:37:46.088+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:37:46.088+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:37:46.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.768 seconds
[2025-09-20T22:38:16.474+0000] {processor.py:186} INFO - Started process (PID=861) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:38:16.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:38:16.477+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:38:16.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:38:17.195+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:38:17.222+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:38:17.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:38:17.236+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:38:17.235+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:38:17.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.790 seconds
[2025-09-20T22:38:47.554+0000] {processor.py:186} INFO - Started process (PID=865) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:38:47.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:38:47.557+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:38:47.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:38:48.150+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:38:48.180+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:38:48.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:38:48.192+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:38:48.192+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:38:48.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.668 seconds
[2025-09-20T22:39:18.580+0000] {processor.py:186} INFO - Started process (PID=869) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:39:18.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:39:18.583+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:39:18.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:39:19.375+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:39:19.399+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:39:19.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:39:19.411+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:39:19.411+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:39:19.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.860 seconds
[2025-09-20T22:39:49.727+0000] {processor.py:186} INFO - Started process (PID=873) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:39:49.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:39:49.730+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:39:49.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:39:50.353+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:39:50.379+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:39:50.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:39:50.391+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:39:50.391+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:39:50.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.692 seconds
[2025-09-20T22:40:20.717+0000] {processor.py:186} INFO - Started process (PID=877) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:40:20.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:40:20.720+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:40:20.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:40:21.327+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:40:21.353+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:40:21.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:40:21.366+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:40:21.366+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:40:21.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.678 seconds
[2025-09-20T22:40:51.686+0000] {processor.py:186} INFO - Started process (PID=881) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:40:51.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:40:51.689+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:40:51.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:40:52.434+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:40:52.465+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:40:52.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:40:52.478+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:40:52.478+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:40:52.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.827 seconds
[2025-09-20T22:41:22.795+0000] {processor.py:186} INFO - Started process (PID=885) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:41:22.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:41:22.798+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:41:22.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:41:23.488+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:41:23.517+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:41:23.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:41:23.534+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:41:23.534+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:41:23.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.767 seconds
[2025-09-20T22:41:53.842+0000] {processor.py:186} INFO - Started process (PID=889) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:41:53.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:41:53.845+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:41:53.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:41:54.504+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:41:54.569+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:41:54.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:41:54.588+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:41:54.588+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:41:54.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.776 seconds
[2025-09-20T22:42:24.917+0000] {processor.py:186} INFO - Started process (PID=893) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:42:24.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:42:24.920+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:42:24.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:42:25.584+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:42:25.618+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:42:25.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:42:25.633+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:42:25.633+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:42:25.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.752 seconds
[2025-09-20T22:42:55.962+0000] {processor.py:186} INFO - Started process (PID=897) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:42:55.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:42:55.965+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:42:55.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:42:56.599+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:42:56.626+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:42:56.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:42:56.642+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:42:56.642+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:42:56.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.714 seconds
[2025-09-20T22:43:21.256+0000] {processor.py:186} INFO - Started process (PID=25) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:43:21.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:43:21.262+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:43:21.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:43:22.153+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:43:22.185+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:43:22.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:43:22.201+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:43:22.201+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:43:22.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.985 seconds
[2025-09-20T22:43:52.802+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:43:52.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:43:52.807+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:43:52.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:43:53.569+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:43:53.596+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:43:53.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:43:53.608+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:43:53.608+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:43:53.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.832 seconds
[2025-09-20T22:44:23.988+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:44:23.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:44:23.992+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:44:23.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:44:24.619+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:44:24.646+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:44:24.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:44:24.659+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:44:24.658+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:44:24.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.697 seconds
[2025-09-20T22:44:55.406+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:44:55.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:44:55.409+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:44:55.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:44:56.095+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:44:56.123+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:44:56.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:44:56.136+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:44:56.136+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:44:56.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.758 seconds
[2025-09-20T22:45:26.831+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:45:26.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:45:26.835+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:45:26.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:45:27.504+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:45:27.531+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:45:27.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:45:27.543+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:45:27.543+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:45:27.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.738 seconds
[2025-09-20T22:45:58.236+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:45:58.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:45:58.240+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:45:58.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:45:59.013+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:45:59.044+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:45:59.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:45:59.056+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:45:59.056+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:45:59.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.845 seconds
[2025-09-20T22:46:29.415+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:46:29.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:46:29.419+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:46:29.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:46:30.166+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:46:30.196+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:46:30.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:46:30.210+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:46:30.210+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:46:30.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.820 seconds
[2025-09-20T22:47:00.578+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:47:00.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:47:00.582+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:47:00.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:47:01.236+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:47:01.263+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:47:01.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:47:01.277+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:47:01.277+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:47:01.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.728 seconds
[2025-09-20T22:47:32.095+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:47:32.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:47:32.099+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:47:32.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:47:32.767+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:47:32.794+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:47:32.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:47:32.807+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:47:32.807+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:47:32.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.738 seconds
[2025-09-20T22:48:03.210+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:48:03.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:48:03.216+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:48:03.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:48:03.926+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:48:03.955+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:48:03.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:48:03.970+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:48:03.970+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:48:03.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.800 seconds
[2025-09-20T22:48:34.733+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:48:34.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:48:34.736+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:48:34.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:48:35.533+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:48:35.562+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:48:35.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:48:35.580+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:48:35.580+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:48:35.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.872 seconds
[2025-09-20T22:49:06.020+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:49:06.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:49:06.024+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:49:06.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:49:06.702+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:49:06.728+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:49:06.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:49:06.746+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:49:06.746+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:49:06.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.754 seconds
[2025-09-20T22:49:37.505+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:49:37.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:49:37.509+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:49:37.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:49:38.149+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:49:38.175+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:49:38.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:49:38.187+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:49:38.187+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:49:38.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.714 seconds
[2025-09-20T22:50:08.363+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:50:08.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:50:08.368+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:50:08.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:50:09.121+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:50:09.146+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:50:09.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:50:09.158+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:50:09.158+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:50:09.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.832 seconds
[2025-09-20T22:50:39.561+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:50:39.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:50:39.565+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:50:39.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:50:40.235+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:50:40.262+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:50:40.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:50:40.275+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:50:40.275+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:50:40.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.749 seconds
[2025-09-20T22:51:10.699+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:51:10.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:51:10.713+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:51:10.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:51:11.453+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:51:11.480+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:51:11.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:51:11.493+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:51:11.493+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:51:11.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.833 seconds
[2025-09-20T22:51:41.887+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:51:41.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:51:41.890+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:51:41.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:51:42.551+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:51:42.580+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:51:42.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:51:42.594+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:51:42.594+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:51:42.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.743 seconds
[2025-09-20T22:52:13.297+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:52:13.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:52:13.301+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:52:13.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:52:13.987+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:52:14.012+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:52:14.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:52:14.024+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:52:14.024+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:52:14.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.764 seconds
[2025-09-20T22:52:44.716+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:52:44.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:52:44.718+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:52:44.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:52:45.367+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:52:45.393+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:52:45.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:52:45.405+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:52:45.405+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:52:45.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.724 seconds
[2025-09-20T22:53:15.776+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:53:15.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:53:15.779+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:53:15.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:53:16.420+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:53:16.446+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:53:16.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:53:16.458+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:53:16.458+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:53:16.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.711 seconds
[2025-09-20T22:53:47.007+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:53:47.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:53:47.010+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:53:47.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:53:47.683+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:53:47.714+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:53:47.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:53:47.744+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:53:47.744+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:53:47.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.764 seconds
[2025-09-20T22:54:18.132+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:54:18.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:54:18.135+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:54:18.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:54:18.835+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:54:18.862+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:54:18.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:54:18.874+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:54:18.873+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:54:18.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.776 seconds
[2025-09-20T22:54:49.258+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:54:49.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:54:49.261+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:54:49.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:54:49.937+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:54:49.964+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:54:49.964+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:54:49.976+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:54:49.976+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:54:49.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.747 seconds
[2025-09-20T22:55:20.363+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:55:20.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/clean_users_dag.py for tasks to queue
[2025-09-20T22:55:20.366+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:55:20.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:55:21.140+0000] {processor.py:925} INFO - DAG(s) 'clean_users_from_lake_dag' retrieved from /opt/airflow/dags/clean_users_dag.py
[2025-09-20T22:55:21.170+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:55:21.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-20T22:55:21.183+0000] {logging_mixin.py:190} INFO - [2025-09-20T22:55:21.182+0000] {dag.py:4180} INFO - Setting next_dagrun for clean_users_from_lake_dag to None, run_after=None
[2025-09-20T22:55:21.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/clean_users_dag.py took 0.847 seconds
